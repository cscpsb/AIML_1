{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "YWIiCh03MP-g",
        "o4yJGdQSMlXW",
        "r_3T--0qOMQi",
        "TQxVH7brUpO0",
        "8Vmhlk4jU0kj",
        "sbGBfdD7U-7N",
        "63T2Wk4tVOS2",
        "OU9Xgm3jIOoI",
        "IPyFszkrti9F",
        "SPZ7Oo3zJCx-",
        "GA5Ko8LntuJV",
        "FbkXjRFh_HB-",
        "Tb2rysoPJXp_"
      ],
      "authorship_tag": "ABX9TyN8VR16wjG+e36LdZW7AelS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cscpsb/AIML_1/blob/main/LLM%20Post%20Training/Fine_Tune_Gemma_using_Hugging_Face_Transformers_and_QloRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Development Environment"
      ],
      "metadata": {
        "id": "TPh9qwEEIdnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install HF libraries, including TRF, Datasets"
      ],
      "metadata": {
        "id": "YWIiCh03MP-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install \"torch>=2.4.0\" tensorboard\n",
        "\n",
        "# Install Gemma release branch from Hugging Face\n",
        "%pip install \"transformers>=4.51.3\"\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \\\n",
        "  \"datasets==3.3.2\" \\\n",
        "  \"accelerate==1.4.0\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"bitsandbytes==0.45.3\" \\\n",
        "  \"trl==0.21.0\" \\\n",
        "  \"peft==0.14.0\" \\\n",
        "  protobuf \\\n",
        "  sentencepiece\n",
        "\n",
        "# COMMENT IN: if you are running on a GPU that supports BF16 data type and flash attn, such as NVIDIA L4 or NVIDIA A100\n",
        "#% pip install flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Jhk94j_EId6X",
        "outputId": "af5f961f-6702-442b-af7f-6917b920d660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: transformers>=4.51.3 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2025.10.5)\n",
            "Collecting datasets==3.3.2\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting accelerate==1.4.0\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate==0.4.3\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting bitsandbytes==0.45.3\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting trl==0.21.0\n",
            "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft==0.14.0\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.70.16)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.3.2)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (6.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (0.6.2)\n",
            "Requirement already satisfied: transformers>=4.55.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.21.0) (4.57.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.0->trl==0.21.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.0->trl==0.21.0) (0.22.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.3.2) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0) (3.0.3)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, fsspec, datasets, bitsandbytes, accelerate, trl, peft, evaluate\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.11.0\n",
            "    Uninstalling accelerate-1.11.0:\n",
            "      Successfully uninstalled accelerate-1.11.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.1\n",
            "    Uninstalling peft-0.17.1:\n",
            "      Successfully uninstalled peft-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.4.0 bitsandbytes-0.45.3 datasets-3.3.2 evaluate-0.4.3 fsspec-2024.12.0 peft-0.14.0 protobuf-6.33.0 trl-0.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "32b2abd5a88a4a119445c52ffe3a66f2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accept terms of use https://huggingface.co/google/gemma-3-1b-pt"
      ],
      "metadata": {
        "id": "GdcgF54lKN25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login into Hugging Face Hub\n",
        "hf_token = userdata.get('HG1')\n",
        "login(hf_token)"
      ],
      "metadata": {
        "id": "Abg7At_fKial"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create & Prepare FT Dataset"
      ],
      "metadata": {
        "id": "o4yJGdQSMlXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use HF datasets library 1. to load dataset 2. to create prompt template\n",
        "to combine Natural language instruction, schema definition, system message for assistant"
      ],
      "metadata": {
        "id": "1DXvJWikNjwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# System message for the assistant\n",
        "system_message = \"\"\"You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\"\"\"\n",
        "\n",
        "# User prompt that combines the user query and the schema\n",
        "user_prompt = \"\"\"Given the <USER_QUERY> and the <SCHEMA>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\n",
        "\n",
        "<SCHEMA>\n",
        "{context}\n",
        "</SCHEMA>\n",
        "\n",
        "<USER_QUERY>\n",
        "{question}\n",
        "</USER_QUERY>\n",
        "\"\"\"\n",
        "def create_conversation(sample):\n",
        "  return {\n",
        "    \"messages\": [\n",
        "      # {\"role\": \"system\", \"content\": system_message},\n",
        "      {\"role\": \"user\", \"content\": user_prompt.format(question=sample[\"sql_prompt\"], context=sample[\"sql_context\"])},\n",
        "      {\"role\": \"assistant\", \"content\": sample[\"sql\"]}\n",
        "    ]\n",
        "  }\n",
        "\n",
        "# Load dataset from the hub\n",
        "dataset = load_dataset(\"philschmid/gretel-synthetic-text-to-sql\", split=\"train\")\n",
        "dataset = dataset.shuffle().select(range(12500))\n",
        "\n",
        "# Convert dataset to OAI messages\n",
        "dataset = dataset.map(create_conversation, remove_columns=dataset.features,batched=False)\n",
        "# split dataset into 10,000 training samples and 2,500 test samples\n",
        "dataset = dataset.train_test_split(test_size=2500/12500)\n",
        "\n",
        "# Print formatted user prompt\n",
        "print(dataset[\"train\"][345][\"messages\"][1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "809b71cd5b734345a58a4c714d3fd7ac",
            "9cd64106d96a45e590685796baaba9c9",
            "8d4cf11da51040dabdf7e8201955cd4e",
            "cd7a8361e6f249dfb0cd36416d321031",
            "169e88623dbd49c38426fc965da15c66",
            "da002fdfad254824a125b0a7e6dca282",
            "6ec3595c253f4d08af8db081687a278b",
            "217e05feb9574f35ad3edd681db3383f",
            "7d9d10edab104cb588b461d95e82ce45",
            "9392dce24ee54c019ccd1ab6ffceac58",
            "cf14d8c633f44148b905139746e4a353",
            "098529eb97444fe8a884d6235442e9b2",
            "13e679c5097045258b86131cd4c8ee40",
            "53febd266bb84699bbac643f13a0c2a0",
            "c76a3c6b127840a0b82fea5d3bc9fb4d",
            "54ca767a414446979df3c18329ec68b8",
            "0c3ac228cb1b42e4a99a2bef4e7e6a1b",
            "f8a9b791a1514f83b60ba4e1e8b04858",
            "2d95431b288a498fa42a2f4c61ca2200",
            "9964ea8c30574fefb9f34127294f7ce9",
            "c7ef654548574aa18e9fe9fcb4e799a2",
            "97d5f8166906457e9ac9be51aeb9358d",
            "5bc522c1b42a4c95b53bd89708ac84ed",
            "48fbc915e7344f189a509a8605bc0aec",
            "3e5a0369857740d6b2d082721bb68778",
            "bd6bb1f4445e499a962484d80bf68c90",
            "d83c76449a9d42af8db0ee3f958f0b44",
            "bc5984234710482ca3630394c7961c94",
            "028f21fdee384efaad86028a0fcaf967",
            "8226cc674c894b1c88c845e05015dc5f",
            "3f9e6415ed834c7384ffed2c29cffea6",
            "13e99ac4fe98494f88ceaa8af309beca",
            "ad113958da434f20b526bff82edf3122",
            "c1970d9eba614095863fb27fa556bf26",
            "bf5377de25a54eb0a0e98988e3710270",
            "9e43c0b75a56414fab4be4862185b626",
            "b17ee1c87c284ffaa14fb2db0fbc025e",
            "7764e03dd53346a5b3809dc0b5303cdf",
            "a712d2dc0c4c4f9aaf838941765fff67",
            "2df0a59181ba40abbff88fbdc5d0cf80",
            "546cf87d35fa479b8a94bdf809f98db4",
            "d0f6cdf79edc40548b6fa62afd051a09",
            "b9f318bb7ca84338884776cda1fbd6f1",
            "803ab67a40ee461799707e1e9e14332f",
            "4ebf0805a232400c828114cf2e92cb79",
            "6ca9274cad5446e39ca025cd9d27bf95",
            "696c30418f7d4b8f8cd23507b9a04e6d",
            "3559804731c54448b3fcf75194b3e618",
            "2a28d2c94436459dae5e78e5ace37fb1",
            "146feabeff284de7b71d6f0b3a7f0c75",
            "83d038e73e194de58700efa323856a0e",
            "4e7f3569ee0d48419a7a55d5e4ced531",
            "98969c78eb7849bb95d344e62dc54963",
            "852dbb82764f4039b2689d3367e2cbe0",
            "ea9800f40bb247a08b51ef494f860983",
            "8c46f525dd03450eabacf92b373a5846",
            "5678437a1c62410f84b666fa830181f6",
            "030c8743ae714cab8e8c0f5e3d470a89",
            "33a885b9ce6b49eba9c75ec322c06ef6",
            "fc180ae2293644d7adfe7fbd5bf0527a",
            "f8283d7b9c604ad48d7c252b6c92bf04",
            "c1aa9c6e1b7c4f33810956c7a86a8752",
            "7def57df43624866882d172fd9915699",
            "976228da475f409d837565e81882ff5c",
            "f4c14d99e4224ea1a7af5a4e5aa863ed",
            "f89d389379c9400fb33452476601ed9f"
          ]
        },
        "id": "oukHA0yoNVAN",
        "outputId": "68ec9dd0-347f-405f-956d-12d7cf073c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/737 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "809b71cd5b734345a58a4c714d3fd7ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "synthetic_text_to_sql_train.snappy.parqu(…):   0%|          | 0.00/32.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "098529eb97444fe8a884d6235442e9b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "synthetic_text_to_sql_test.snappy.parque(…):   0%|          | 0.00/1.90M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bc522c1b42a4c95b53bd89708ac84ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1970d9eba614095863fb27fa556bf26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/5851 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ebf0805a232400c828114cf2e92cb79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c46f525dd03450eabacf92b373a5846"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT SUM(donation_amount) FROM Donations WHERE donor_name LIKE '%India%' AND donation_date BETWEEN '2021-07-01' AND '2021-09-30';\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune Gemma using TRL & SFTTrainer"
      ],
      "metadata": {
        "id": "r_3T--0qOMQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Gemma model & Tokenizer from Hugging Face & Initialize the quantization configuration"
      ],
      "metadata": {
        "id": "0uZxd7fhOY4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForImageTextToText, BitsAndBytesConfig\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"google/gemma-3-1b-pt\" # or `google/gemma-3-4b-pt`, `google/gemma-3-12b-pt`, `google/gemma-3-27b-pt`\n",
        "\n",
        "# Select model class based on id\n",
        "if model_id == \"google/gemma-3-1b-pt\":\n",
        "    model_class = AutoModelForCausalLM\n",
        "else:\n",
        "    model_class = AutoModelForImageTextToText\n",
        "\n",
        "# Check if GPU benefits from bfloat16\n",
        "if torch.cuda.get_device_capability()[0] >= 8:\n",
        "    torch_dtype = torch.bfloat16\n",
        "else:\n",
        "    torch_dtype = torch.float16\n",
        "\n",
        "# Define model init arguments\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"eager\", # Use \"flash_attention_2\" when running on Ampere or newer GPU\n",
        "    torch_dtype=torch_dtype, # What torch dtype to use, defaults to auto\n",
        "    device_map=\"auto\", # Let torch decide how to load the model\n",
        ")\n",
        "\n",
        "# BitsAndBytesConfig: Enables 4-bit quantization to reduce model size/memory usage\n",
        "model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=model_kwargs['torch_dtype'],\n",
        "    bnb_4bit_quant_storage=model_kwargs['torch_dtype'],\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = model_class.from_pretrained(model_id, **model_kwargs)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\") # Load the Instruction Tokenizer to use the official Gemma template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650,
          "referenced_widgets": [
            "2277d07655524b74a0fff9003af2f9b6",
            "9f5c220fb8b148e59497b4c787fdb92a",
            "e77888008a6840bfbab301b7c7d23758",
            "f62a9b2a5c48419f9ccdd69fd6ef1833",
            "8f1dbef41ff8456ea22fc9b9ee491230",
            "1fff3cb1c2ba48fba7f5719e598fe7c8",
            "d723342702fc4011a4772eadc245c8fb",
            "087300cf9ba14e6f90b5939437cad869",
            "34eb68abe0a74103a4249972e334abcb",
            "56bef0802bc74d0293da3646635100b2",
            "013be0e653da47648ab7aa110b5ef3fe",
            "b4d55aeb6d214600b50a5a21651d8c54",
            "1b921ad275414cb2af4f6e5bf3911675",
            "a37ebb084a414cdc9fbfc927f69a5de6",
            "b5d5fd2b6db94df4b848c799c091e6a1",
            "9296c967c60f4113b3d56fa1ec82a247",
            "c5ae08f8b9a44d94ab84d5ddeba19d08",
            "e8ab4ef2bcf84cab8142e048c5816876",
            "3106519357904b45a95f8680f7964160",
            "27ef24e92b144f8fb84056c7a8d3cba7",
            "dc3ccc86212c49a2827f994a69e686a3",
            "c0fd180abf8241b98f61ddd9b3b5700b",
            "54bad009bbc94c81ac8a356d0200052c",
            "9a3178bceb7e4165ba34f3dffbfbed44",
            "3771991ae1fa41eeab9b25031ab7cc21",
            "d8dd3e370db1476aab0065f19ee1ba41",
            "ca14b9564c214187a4e7e75eb860928d",
            "27a28597c0cc47ee8cae330fa3e8736c",
            "85acc9f08bb240e98305788b6d4794ff",
            "dd5ac0648ba24094aaa585587dc8a46a",
            "d796120849e645c1bc5c324063fcfe44",
            "3386df42267d4785a0d34a5584b9df17",
            "737fccf89a7c4d148e2badcf75a3badb",
            "ca7519eb49a349f0bc98423a42d09456",
            "6a0065a03d844c159897048da3f846e8",
            "45950eb33e8342a6bafa0c7b783963e2",
            "16e6fbabe95c476aaf6b81ae813cc071",
            "db221cc977994ed68efce167bb0a05b4",
            "d8665a92514d40d2b0ab722dcb26aad6",
            "71728a3e8c3d4e2bb22b0ce2e2fa2a4a",
            "6069d0e9e99d439fa0f80ff62b91c30d",
            "b957ac86a058483dbecb664d50cce2fc",
            "37142389706147ca89c2658cc0463bff",
            "7db2d427b6c94758a3f834a5300c52f0",
            "dfa5095c870f4fc3b679b8df8bdee370",
            "ac4e9f80ebc74500ad17aae0ebf1edce",
            "02ed2d3f35b34f589d2fd4e9d9c9fdbf",
            "4c37202a57d84472a648971d590cbf53",
            "c132251444f54f768241bcf55ef4f544",
            "48f058fd0553414ea91459be350c710d",
            "95d06d7c165e4a44a216b017176c97f6",
            "f15ba45b89914208bded8a412fbae019",
            "12d104205a1348f1b4ed9c22eecfd08d",
            "f54a5c53d8e64222acf9366f83f0f6eb",
            "1d4980aa22ce4e1f9e39317cbb5bfe69",
            "66f62cffea714ced98b0e6d43454ee41",
            "6282c427ad4c4829a91aad93cd57d188",
            "9ec879cc564e402294be22da763ce97e",
            "0bce693a8d514b18a65a139861d5af3e",
            "c00bcd519d7249679f098be76c33d2b9",
            "cf4c1c592e9e4d0e972d1d7ae114bd05",
            "5f5eaa423a7e43cdbe9543ca20b753ae",
            "157126ce04b14d16808fe6e37e2a1d1b",
            "ead25909bb804c0f8d6d279b3cffbf1d",
            "796e8df2272943ec8fb1a06136219de2",
            "5c498b8b41794b4999bf6cba6522296b",
            "e6d1733d0fd34b1fa55c4f752711bc23",
            "322ae763ba3e4def918a267efaad789e",
            "9d444bc16d3a4271ba91f6e4ec0f1064",
            "05c9aa17fe764b0da939a3a3dacfbd45",
            "c7a2d5ac2b5248cba0bcec825d32cf6f",
            "7d6ba33868e747f0b63156f171e73d23",
            "b68c8d790d0849e6b3a295a4e4f70293",
            "69dd0cdd287e4c7b95f39320ffbceee6",
            "3f99cb5d5a5342709445a5aaec8171df",
            "79c681cbffa6454395b50ba7dcc6b6a5",
            "1889ad8e93e14c0c92d9bc5c16edae2f",
            "29ceb04d25ea459eba83d325931874ac",
            "0a2931a79fe14f7993466b7b7ca27753",
            "d05b78918f824c40a7932bb949adffe6",
            "bca9f214acef45308dc896ecf76f38ae",
            "42ad541b43584986ac418cb725779e75",
            "afc9358bc9684aa4a40dbb9e7a8328ef",
            "e5d322fefe3e4039ba378097ca14d967",
            "568e1c7fe2c949b79e7607e8cd636c18",
            "98ffe74f62f04997a5e5c98eab758cbe",
            "7a6ec12bc0f246b18067ef008a2ba6f3",
            "3936f1a2a6a14471bae69d2631750059"
          ]
        },
        "id": "Oh-4WthhOSKa",
        "outputId": "de890c71-de80-4e38-9b0f-167a0d67bc97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/880 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2277d07655524b74a0fff9003af2f9b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4d55aeb6d214600b50a5a21651d8c54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54bad009bbc94c81ac8a356d0200052c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca7519eb49a349f0bc98423a42d09456"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfa5095c870f4fc3b679b8df8bdee370"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66f62cffea714ced98b0e6d43454ee41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6d1733d0fd34b1fa55c4f752711bc23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29ceb04d25ea459eba83d325931874ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create LoRA config to provide to SFTTrainer"
      ],
      "metadata": {
        "id": "TQxVH7brUpO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    r=16,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    modules_to_save=[\"lm_head\", \"embed_tokens\"] # make sure to save the lm_head and embed_tokens as you train the special tokens\n",
        ")"
      ],
      "metadata": {
        "id": "f5j3etmoUu8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SFT Config : Define Hyperparameteres to use in SFTTrainer"
      ],
      "metadata": {
        "id": "8Vmhlk4jU0kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig\n",
        "\n",
        "args = SFTConfig(\n",
        "    output_dir=\"gemma-text-to-sql\",      # directory to save and repository id\n",
        "    max_length=512,     # max sequence length for model and packing of the dataset\n",
        "    packing=True,  # Groups multiple samples in the dataset into a single sequence\n",
        "    num_train_epochs=3,                     # number of training epochs\n",
        "    per_device_train_batch_size=1,    # batch size per device during training\n",
        "    gradient_accumulation_steps=4,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
        "    logging_steps=10,                       # log every 10 steps\n",
        "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
        "    learning_rate=2e-4,                     # learning rate, based on QLoRA paper\n",
        "    fp16=True if torch_dtype == torch.float16 else False,   # use float16 precision\n",
        "    bf16=True if torch_dtype == torch.bfloat16 else False,   # use bfloat16 precision\n",
        "    max_grad_norm=0.3,               # max gradient norm based on QLoRA paper\n",
        "    warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper\n",
        "    lr_scheduler_type=\"constant\",      # use constant learning rate scheduler\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False, # We template with special tokens\n",
        "        \"append_concat_token\": True, # Add EOS token as separator token between examples\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "hUg_wVs_U5HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create SFTTrainer"
      ],
      "metadata": {
        "id": "sbGBfdD7U-7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "# Create Trainer object\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    peft_config=peft_config,\n",
        "    processing_class=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "c06190eda941448f9e11df2006ed5c90",
            "64d222da8d6a411a8a903b7bc03dc12e",
            "4b4698d710ba4506b82b603407ca8a5f",
            "02416f43016e4046adfb90a0d10b32e4",
            "73e95d6670f54bf8af0f0cae958e09fa",
            "57f14bd983894286a696240108c98df0",
            "ea1daea255b241bd8a86a011d417940c",
            "3ac9a64e0764430d914f4d06b28cc0f7",
            "c103c6633e3d440f9bb8ecaa240898e7",
            "2cd052c574214d809b5828f4b5641bd8",
            "dc305f71855a4499b7365e53b27dfa36",
            "c18614710d9741c0b07ce8dc108ad419",
            "bc2808dca4b64548bea6536a8cc92d23",
            "67a39f7843394584998d7620f9021e89",
            "db279de284e342b48b7f077a65661308",
            "b071be5baf9644d594d4029e91df7d92",
            "bbe42234ee104914bea84a1ea8a74873",
            "e2994024b1684f7586e54b8817e6c5c1",
            "647b3de028b14c7ebccc132c1470b514",
            "8255b2ff4fdb4f36863cef9443297bc9",
            "293a56f2b95b461081c0439f04dc0b15",
            "6da5195abb2446fe96a541115ceca1ba"
          ]
        },
        "id": "zLPPDOMcVAY8",
        "outputId": "1bcd57cf-7129-4f7d-e918-b7719f023a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:453: UserWarning: Padding-free training is enabled, but the attention implementation is not set to 'flash_attention_2'. Padding-free training flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation='flash_attention_2'` in the model configuration, or verify that your attention mechanism can handle flattened sequences.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:495: UserWarning: You are using packing, but the attention implementation is not set to 'flash_attention_2' or 'kernels-community/vllm-flash-attn3'. Packing flattens batches into a single sequence, and Flash Attention is the only known attention mechanisms that reliably support this. Using other implementations may lead to cross-contamination between batches. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation='flash_attention_2'` or `attn_implementation='kernels-community/vllm-flash-attn3'` in the model configuration.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c06190eda941448f9e11df2006ed5c90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Packing train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c18614710d9741c0b07ce8dc108ad419"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Training by calling train() method"
      ],
      "metadata": {
        "id": "63T2Wk4tVOS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training, the model will be automatically saved to the Hub and the output directory\n",
        "trainer.train()\n",
        "\n",
        "# Save the final model again to the Hugging Face Hub\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d0b70958b8984a67861dd4533099bcdf",
            "41bd4349a4934e499e0acd8f712f2ce4",
            "e4eb12f19957472892ac6e73af687702",
            "8152abe35ca24964981cdd3657d7c8af",
            "d599a66a2833471db42e71cac75f3418",
            "d848f742d6b44aba8920848c96979397",
            "37fcbd0aa2ff481589652cb0e5e30bd4",
            "58045b476fb0404595d31901cb85a6f9",
            "1f9f55d163b94a91af85b616898ff0a9",
            "c91056ff907149b6ace659d598aef2f1",
            "75faa4e5232e43e087ffa754ecd1a72b",
            "c489b356d6ed4f11a35565fc6bf51dd3",
            "7622700786ce47578ab3d56ac3e740f3",
            "50d5faf56b4642a8b354a9f2de7a6d6e",
            "6823fa3e841a4dd9ba9a99a3dc876fc6",
            "09eb0fd2d42b42fe8e6d7dd0a0a8460e",
            "e1d5b19c0da8491788bd16edcdacf02e",
            "917d8dab25514ff0bcd595ef167b5b57",
            "304a50a7cd8a47a8addde79d800bc184",
            "5994a529cb554b17979c9ee96c2eb816",
            "1ad592de31154beb92dd5e281765242e",
            "cb8266fa999a4d3991a85339646210b1",
            "79088d75df3d484a878169cd3101f37b",
            "22b06e37755d407c87610b74396130f0",
            "1c66740e9d0f43fb98be0870599b5bfd",
            "ba17b56533d94befa644556b7ed135c7",
            "74348cca207b499db23e7586a45d2cac",
            "2e85ce820f9e4c379a232710ed2c4bd2",
            "984d46b32712475cbf76ff3b9eace887",
            "f51b5bba22914b0f9187412656bc8c4a",
            "566e0a5ca66f4002bbcc384c696a7815",
            "8e1ad790a34749839da15959a74cd02d",
            "98959437dac8485f93f96c9774881354",
            "1ee5d07ebf7444d2b5c66a067eba3130",
            "91f321701fb54a20a1b00261399e1717",
            "aed7fbc9113542d2a2d20984db0c61cc",
            "2c554982b6b5462fb6c45657a0f91515",
            "06dc82e6590a4f97bbda56575d56637e",
            "af9125d2850b4911a71d31ace379a186",
            "8d1e083b58fb41f2b98b5ec0a1f752a6",
            "0eec7dcb144349c6b0095b9691454497",
            "3fda9d83853f44988d92af882984da7a",
            "74a50339f92b4e459be3980fec2fa021",
            "779f3c13830644bb9eb4d3d1867b05ef",
            "f53455537f0144698c0b10b0d312b0f8",
            "59277130a3314de2bdb5cf1e1a04d3fa",
            "c3a4fa602fd743baae2df59d84371eab",
            "674e8edd79cc4799ad3a2361731e8afb",
            "cf2259f2da6441a48f1ed6b6b7caf139",
            "85ed87f51ea24a6993a689a9f7471e5a",
            "a219ed02aec84bb08999bc35e116ce9f",
            "b56bc50a60fc46c983b19b9b5a0dbd91",
            "eafa16a47c9b475fb2d2236a6d5c59fd",
            "7414e16039024ba8ad1e58c400eb5d05",
            "730e1c6d938b4428b26b765797968f93",
            "93121fade88b40aea6626d2767a98e3d",
            "ad6ba98cfded4fc395b61418d2be9a7d",
            "81e4982f7c2149f9a162fef0fd1ea2df",
            "35fe44af6a3a4e91ad79c376e9fd6c2f",
            "4dac3a15914b49e48c7a4889feca09c3",
            "72f81c6b618a4eb19d2c568b5453c11a",
            "09a89429246846e78fb558777d18f01f",
            "10a130f5c6b04d23bb55bc5dd6a67340",
            "a069bb8fc3354bffbce1a8408c8d2fe3",
            "46da2a9d2ae5498a880266fc8fff39d5",
            "7a4385609c0b433cb55743030caaf804",
            "8b0cd227bd894c53b81f0ce7ff98f97b",
            "528150fb9fa044b6ac18036fbcc609ca",
            "b9b45e84799d4fb2b52b954874b4f246",
            "5daccef72be148ad92df2c195ddc8eb5",
            "b1c41b1242224314b7e76e6b5d43f11a",
            "78289744b0d245b6aec6975af545ee97",
            "1386f4d75cd14ddcad1ba7689528bcf8",
            "0e14647e287f4c6180af82e748b2389f",
            "3ebb9bd30098428ebf1028a517a57311",
            "50e4b1a2474b48b99fae7c5e7beff6be",
            "2f9f1c61a04f44e6a6cd0c4d0f5d508a"
          ]
        },
        "id": "tiCmPzRgVN1q",
        "outputId": "f93ca172-ecd7-4acd-c063-3d2398c57740",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3270' max='3270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3270/3270 2:46:47, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.569500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.529600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.556900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.524500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.506800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.528400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.483200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.497500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.481400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.485600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.495600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.486000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.508900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.490800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.446600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.499200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.474000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.503200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.469900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.464500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.456800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.437800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.479400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.466200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.464900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.460900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.467900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.448300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.476200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.463800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.460500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.484300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.432500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.464300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.447400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.458700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.491000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.467900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.473400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.445600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.443200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.420800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.442400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.450800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.451900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.434300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.425800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.443400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.450900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.456200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.427700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.442700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.426300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.412300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.442900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.440800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.437600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.453100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.423200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.418300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.450500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.412400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.466700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.444100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.449400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.437300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.429100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.423200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.459300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.425700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.418200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.408500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.452700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.442600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.461600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.408600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.410800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.426900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.434500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.422200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.428800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.443300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.447200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.426800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.388300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.418700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.410600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.429500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.423500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.427400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.426200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.408900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.422900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.403000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.420300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.434200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.443300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.418600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.442800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.408800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.405400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.313300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.318200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.336900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.320700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.331600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.317900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.322700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.314600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.311600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.331200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.308800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.329300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.314100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.326700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.328000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.316500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.335100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.332600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.315000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.363700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.316000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.326500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.321200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.331000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.330200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.318100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.318400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.328700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.328400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.334000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.335100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.322000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.322500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.320500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.321500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.329500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.359300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.324400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.335900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.330500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.318700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.337300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.312600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.334200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.310200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.317600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.330300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.334100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.329600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.332600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.327800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.315700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.326200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.321200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.339900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.330600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.328900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.333000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.310500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.323100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.325500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.331400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.333400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.333300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.322000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.336100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.326800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>0.337600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.339200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>0.336300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.343000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>0.313300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>0.346200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.336500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>0.325800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.350400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>0.337000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>0.361300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.339500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>0.322200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>0.338600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>0.321200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>0.328700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.329300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>0.338000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>0.315900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>0.325500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>0.323400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>0.331400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>0.337500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>0.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>0.319400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.327500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>0.321900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>0.341600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>0.325600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>0.329100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.340400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>0.333900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>0.330600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>0.333500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>0.248500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.251800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>0.246300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>0.245200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>0.247000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>0.243700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.248600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>0.242800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>0.246800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>0.250300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>0.242400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.248300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>0.248200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>0.259700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>0.243400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.250300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.250500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>0.246300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>0.258600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>0.250700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>0.245000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.256100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>0.253800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>0.257500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>0.265400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>0.249200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.247500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>0.245800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>0.256000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>0.259700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>0.251400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.265300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2510</td>\n",
              "      <td>0.264000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2520</td>\n",
              "      <td>0.258100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2530</td>\n",
              "      <td>0.263700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2540</td>\n",
              "      <td>0.264400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.259900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2560</td>\n",
              "      <td>0.239000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2570</td>\n",
              "      <td>0.259200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2580</td>\n",
              "      <td>0.259200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2590</td>\n",
              "      <td>0.265100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.254600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2610</td>\n",
              "      <td>0.257500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2620</td>\n",
              "      <td>0.265300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2630</td>\n",
              "      <td>0.257600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2640</td>\n",
              "      <td>0.251000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.258800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2660</td>\n",
              "      <td>0.245800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2670</td>\n",
              "      <td>0.267100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2680</td>\n",
              "      <td>0.275600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2690</td>\n",
              "      <td>0.255200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.256500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2710</td>\n",
              "      <td>0.254600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2720</td>\n",
              "      <td>0.252100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2730</td>\n",
              "      <td>0.254000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2740</td>\n",
              "      <td>0.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.248600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2760</td>\n",
              "      <td>0.266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2770</td>\n",
              "      <td>0.254300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2780</td>\n",
              "      <td>0.267500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2790</td>\n",
              "      <td>0.262200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.258000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2810</td>\n",
              "      <td>0.261300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2820</td>\n",
              "      <td>0.268000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2830</td>\n",
              "      <td>0.251400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2840</td>\n",
              "      <td>0.251600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.270900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2860</td>\n",
              "      <td>0.255600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2870</td>\n",
              "      <td>0.255200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2880</td>\n",
              "      <td>0.256200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2890</td>\n",
              "      <td>0.260600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.258000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2910</td>\n",
              "      <td>0.253500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2920</td>\n",
              "      <td>0.262100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2930</td>\n",
              "      <td>0.282000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2940</td>\n",
              "      <td>0.257700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.268300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2960</td>\n",
              "      <td>0.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2970</td>\n",
              "      <td>0.317300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2980</td>\n",
              "      <td>0.265900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2990</td>\n",
              "      <td>0.266100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.270200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3010</td>\n",
              "      <td>0.260300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3020</td>\n",
              "      <td>0.265100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3030</td>\n",
              "      <td>0.270100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3040</td>\n",
              "      <td>0.275300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.266400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3060</td>\n",
              "      <td>0.270700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3070</td>\n",
              "      <td>0.273400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3080</td>\n",
              "      <td>0.261200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3090</td>\n",
              "      <td>0.275800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.279000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3110</td>\n",
              "      <td>0.260300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3120</td>\n",
              "      <td>0.267400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3130</td>\n",
              "      <td>0.273200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3140</td>\n",
              "      <td>0.262600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3160</td>\n",
              "      <td>0.260900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3170</td>\n",
              "      <td>0.269100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3180</td>\n",
              "      <td>0.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3190</td>\n",
              "      <td>0.261400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.278000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3210</td>\n",
              "      <td>0.269700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3220</td>\n",
              "      <td>0.255100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3230</td>\n",
              "      <td>0.276600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3240</td>\n",
              "      <td>0.272700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3260</td>\n",
              "      <td>0.267900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3270</td>\n",
              "      <td>0.273800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0b70958b8984a67861dd4533099bcdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c489b356d6ed4f11a35565fc6bf51dd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...-to-sql/training_args.bin: 100%|##########| 6.22kB / 6.22kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79088d75df3d484a878169cd3101f37b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...158955.5192e6358283.242.0: 100%|##########|  115kB /  115kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ee5d07ebf7444d2b5c66a067eba3130"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...xt-to-sql/tokenizer.model: 100%|##########| 4.69MB / 4.69MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f53455537f0144698c0b10b0d312b0f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...adapter_model.safetensors:   1%|          | 16.8MB / 2.47GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93121fade88b40aea6626d2767a98e3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...ext-to-sql/tokenizer.json:  50%|#####     | 16.7MB / 33.4MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b0cd227bd894c53b81f0ce7ff98f97b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save full model for inference time use\n",
        "! 30GB of cpu memory is needed"
      ],
      "metadata": {
        "id": "OU9Xgm3jIOoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from peft import PeftModel\n",
        "\n",
        "# Load Model base model\n",
        "#model = model_class.from_pretrained(model_id, low_cpu_mem_usage=True)\n",
        "\n",
        "# Merge LoRA and base model and save\n",
        "#peft_model = PeftModel.from_pretrained(model, args.output_dir)\n",
        "#merged_model = peft_model.merge_and_unload()\n",
        "#merged_model.save_pretrained(\"merged_model\", safe_serialization=True, #max_shard_size=\"2GB\")\n",
        "\n",
        "#processor = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "#processor.save_pretrained(\"merged_model\")"
      ],
      "metadata": {
        "id": "jQuGKCWiIQvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_Force Push model & tokenizer to HF Hub try"
      ],
      "metadata": {
        "id": "Ii-KAKWaIlKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    from peft import PeftModel\n",
        "\n",
        "    # Assuming 'model' is your QLoRA-trained PeftModel\n",
        "    model.push_to_hub(\"UncleDoppler/Gemma-text2sql\", safe_serialization=False)\n",
        "    tokenizer.push_to_hub(\"UncleDoppler/Gemma-text2sql\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "hLbTCIJ1ssZJ",
        "outputId": "b302c5c1-646c-4617-8011-5dace418a3cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The weights trying to be saved contained shared tensors [{'model.embed_tokens.original_module.weight', 'lm_head.original_module.weight'}] that are mismatching the transformers base configuration. Try saving using `safe_serialization=False`, setting the `_dynamic_tied_weights_keys` attribute for affected modules, or remove this tensor sharing.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3385178288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming 'model' is your QLoRA-trained PeftModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UncleDoppler/Gemma-text2sql\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UncleDoppler/Gemma-text2sql\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4342\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_memory_footprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_buffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 )\n\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_shard_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_shard_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_serialization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# Update model card if needed:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   4199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4201\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m   4202\u001b[0m                     \u001b[0;34mf\"The weights trying to be saved contained shared tensors {error_names} that are mismatching \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4203\u001b[0m                     \u001b[0;34m\"the transformers base configuration. Try saving using `safe_serialization=False`, setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The weights trying to be saved contained shared tensors [{'model.embed_tokens.original_module.weight', 'lm_head.original_module.weight'}] that are mismatching the transformers base configuration. Try saving using `safe_serialization=False`, setting the `_dynamic_tied_weights_keys` attribute for affected modules, or remove this tensor sharing."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before testing memory cleanup\n"
      ],
      "metadata": {
        "id": "8Q7NcbQyVI_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# free the memory again\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "eEYbI-nCVMer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Model Inferecne"
      ],
      "metadata": {
        "id": "IPyFszkrti9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model with PEFT adapter"
      ],
      "metadata": {
        "id": "SPZ7Oo3zJCx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForImageTextToText\n",
        "from transformers import pipeline\n",
        "\n",
        "# Update model_id to the Hugging Face Hub repository ID\n",
        "model_id = \"cscps/gemma-text-to-sql\"\n",
        "model_class = AutoModelForCausalLM\n",
        "\n",
        "# Check if GPU benefits from bfloat16\n",
        "if torch.cuda.get_device_capability()[0] >= 8:\n",
        "    torch_dtype = torch.bfloat16\n",
        "else:\n",
        "    torch_dtype = torch.float16\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = model_class.from_pretrained(\n",
        "  model_id,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch_dtype,\n",
        "  attn_implementation=\"eager\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "hGSqrJCwtlnc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "05543ab5c2244c78a36f4e33bba2e18f",
            "f04f25aa4c3b4268baa89d220472332f",
            "f6b9a32fd11641649b9f083eada294a3",
            "efba5bd53fcb4d4aba3acc93d321ec54",
            "08823fb478474bbb86d55661976e0d63",
            "44c35927e53a4e8a9d2062add7f784b0",
            "8b90e1e0824f4434944be09e86b7bcbe",
            "7bf1481f95344234b024192d141b3bc7",
            "860d0b00194c4281b585e7eb31a86ab8",
            "b7bcc5f2f3004b82b13830aa522abc55",
            "2368a94e42104c82bd97348c795dfadf",
            "144d82bcd71641bea24db5ad110f2db5",
            "ef6b565ddfe443969e7c8827643e2ab7",
            "8e1b9cfcfddc430b8628ae1636d8f67c",
            "6dd23acb50144196951afbf6a31381cd",
            "0118bdb1897145278e04c338882c9592",
            "cb60495cafbb41bcac556e43b40fda93",
            "434b72fd7efe49f7a0f9c2dbe958bd5e",
            "b5d0cc8bd46447ce907dcae768f0dc2c",
            "b8c4bcc1128c408db8471665b8c4f8cf",
            "2a4861ec05ad4ac8ad3f5c3789557253",
            "fae2a4ab269e4b8bb62b1d04f3350c34",
            "a0b5aa9644e14131b6b44f84e1388284",
            "5e137b74c0fe475aa68f4da4e05db559",
            "8db467800d1849ba9ca12e20b964d0a5",
            "e8c86f65b8bc4783900a43f51547f228",
            "1c03408986f44935a25566e76c14e78e",
            "9e70eb4d8cd8440fb42ece2d2ed05643",
            "75b23e6b4c384e5fb9218b511eb5f7f5",
            "1075768eba27482a9fe468db051e1575",
            "e8bf2e486c5544b3a0f4e2b7359e826f",
            "64f757fdb465451da49def8fce9a8173",
            "ad684cddfa864cb4b50e1bbf8be376d9",
            "420b47feb50d43aab3427e0d443b86d9",
            "cfe4e22ad53c411699c4d43c86139180",
            "2f764f5cdc3d43098dcb88edf48a7802",
            "9f37c35f8963470f9cb8ac36b4c1aeea",
            "259c4f8f71864158bdd53da0ba0af579",
            "3aca6483013a42398c02a26a7101585e",
            "223f69531ba14968a6a5bb26a6b2af9e",
            "228aa8f94239499bad30b9d63026b1bb",
            "3d92e66acaa04f3fad84b96a7524de47",
            "75a39bdf108e443ab47d439efdea5afe",
            "fcf1c349f78345248d369c2183e8bf9d",
            "cde1f80190404299bb5e012efaf98d39",
            "7368fe413b4e41bdb550e97a368e5359",
            "4c7945901df24232a60fb3a0dfd2d173",
            "ea870300afcc4407bee5b89857ab0720",
            "7dddc0509512477b8394496fb4f58f0e",
            "9d4f626b2bd14b7787fbed6e3f330e73",
            "b7fea1c430d14cb5a282ee4d307b33d3",
            "062017e378ce4c9ba4400ea0672415e1",
            "b89998d91f8f4e61a0d4300cc0324df9",
            "3ce0d316007543d79f1e96d63e848a46",
            "ae4c26bae67449a29f7ae72345c697ed",
            "d495198da76540f8a3b0bc5561073305",
            "66cb166752a6499fb7379453502ac3f9",
            "4687147792444850810c3751e1964260",
            "6a59d6e8cf304d1080fe4de195669ef1",
            "280110c0173f412a97d04c7983248521",
            "7e3f6dfa561d4a4cb2bfc70d2dddf2cd",
            "52175216bd1640f3934db11971e995c8",
            "da4af5deebbe4ce792b075b27fa61a11",
            "e1cb35966e214faaa74a5c8bab94d1f2",
            "e0846f8da8ed4b6386ccede5048242b3",
            "f4475da664e24fd1a6916c4a87b26bb7",
            "d58f0c39a88149ea8dbd8467dd0717e8",
            "54788825c1bd4d8fb1fc54c157874d1a",
            "968a52cbca874fd38627c67007eb49be",
            "7f31de724bb641e58297ebf61715aeed",
            "5a2298c37f744220ba0b5a8910f6a42b",
            "9618c06c81264cdbb74a998286474b5f",
            "04ee330c9c474710b6c2682d06abfa81",
            "6ade55772a634ec48ce24aef1daf0070",
            "b0f45e5301da4df497a4aa5779d69026",
            "9bcfcd1d7fb645b580ef01020ae42638",
            "e1ab629a87044472945e9e743e89be2c",
            "490d902ace4f4406912022f64551429a",
            "f4122e8df5564416957ff7e4c17a4e8b",
            "6f98786faa214d3b9d631a55a62dc8d4",
            "2804466c81e54f70a9674d5d7f5da637",
            "aae3ea80c5b84be5a968f0167bec73aa",
            "7fb2428169c74feaaea5a9e21bd113e7",
            "1256faa89722469290459ab6bef67249",
            "e82a273f7580405e9ef1db389b4264cb",
            "96cf5360ff1b48f5b6ed7b34b449ff07",
            "0cf4137a90d548a5a53ea035f633a98a",
            "56c988039e52449490527331b7abcfaa",
            "dc200728fb54477098e5fb8ba47191fc",
            "b2167c3711604d928cc51eee49484a12",
            "1b18f5b032ce43dcbc72d47c45584f6f",
            "b23f1fabbc7248b9a10e6245dba6e571",
            "16ebe3b3a4e4482eaad4e73400f2dc6f",
            "88afebe3ad084c57ac2c75f21ffb807a",
            "76967fe618c8405ba34e96a2db6f44a3",
            "f662e9c106854212b03cc206bd907328",
            "d5c9d9c78ffe4cee8a8798bfb5178684",
            "ee4eb6c18af5432f94689db57b3781a2",
            "a1300954612d4a949ed8a950fda83968",
            "9b0e7b8c1a5145b997cf691258195e3c",
            "b30c2488e68e47f88bc64656d8eb9ab2",
            "b44d2b24fbfb495dbf49d989a513dc31",
            "6aa9c9fce1114d9c9fc7dda2811d265f",
            "8b8a5989dfce49c79f77c6b200b6f850",
            "5d306e9b802c438e99a73aa6a8017620",
            "21b860b3c4124b149b2a01b011f92bc9",
            "e7226074452545dab3d9b1cb6127e808",
            "44fdac4952934cce8bedf5cd20e84802",
            "b54515bbc3b14b569990f7fdb1757d5c",
            "8752f831425c43428b01120fd66acaa7",
            "e90f685254534cc181ad3787991e94c7",
            "c1ca7779461048caa6d345a0fc9b3712",
            "76878d86f52a47858dcde88b96bfc403",
            "0d615021d90645d4a42d2c126db46106",
            "9ef4b3cb0c7349d4a8de5ec1db73845c",
            "bffc812535f6481ababe6a787aad65c6",
            "2f415c96338c4007aaa6619297cf9b2c",
            "e94acbb7c4944b9dbcb72f979a734d43",
            "b849a7e3871c41ebb073d06892dc00ed",
            "f86599d2bb914a28b171dbf16cdc9160",
            "7544d37107fa4d27b31bb798edbc4f13"
          ]
        },
        "outputId": "5e0432c4-266e-486a-fa59-6c042f3ac45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05543ab5c2244c78a36f4e33bba2e18f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/880 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "144d82bcd71641bea24db5ad110f2db5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0b5aa9644e14131b6b44f84e1388284"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "420b47feb50d43aab3427e0d443b86d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cde1f80190404299bb5e012efaf98d39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d495198da76540f8a3b0bc5561073305"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d58f0c39a88149ea8dbd8467dd0717e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "490d902ace4f4406912022f64551429a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc200728fb54477098e5fb8ba47191fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b0e7b8c1a5145b997cf691258195e3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e90f685254534cc181ad3787991e94c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load random Sample test datatset & generate SQL command"
      ],
      "metadata": {
        "id": "GA5Ko8LntuJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "import re\n",
        "\n",
        "# Load the model and tokenizer into the pipeline\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Load a random sample from the test dataset\n",
        "rand_idx = randint(0, len(dataset[\"test\"])-1)\n",
        "test_sample = dataset[\"test\"][rand_idx]\n",
        "\n",
        "# Convert as test example into a prompt with the Gemma template\n",
        "stop_token_ids = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "prompt = pipe.tokenizer.apply_chat_template(test_sample[\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "# Generate our SQL query.\n",
        "outputs = pipe(prompt, max_new_tokens=256, do_sample=False, temperature=0.1, top_k=50, top_p=0.1, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "\n",
        "# Extract the user query and original answer\n",
        "print(f\"Context:\\n\", re.search(r'<SCHEMA>\\n(.*?)\\n</SCHEMA>', test_sample['messages'][0]['content'], re.DOTALL).group(1).strip())\n",
        "print(f\"Query:\\n\", re.search(r'<USER_QUERY>\\n(.*?)\\n</USER_QUERY>', test_sample['messages'][0]['content'], re.DOTALL).group(1).strip())\n",
        "print(f\"Original Answer:\\n{test_sample['messages'][1]['content']}\")\n",
        "print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCHfyMVBtwmX",
        "outputId": "4e1a44b2-ddf7-4ed7-a358-1e9401774c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            " CREATE TABLE network_investments (investment_id INT, investment_amount FLOAT, region VARCHAR(20), investment_date DATE);\n",
            "Query:\n",
            " What is the year-over-year growth in network infrastructure investment for the region of Ontario, Canada?\n",
            "Original Answer:\n",
            "SELECT (SUM(CASE WHEN YEAR(investment_date) = YEAR(CURRENT_DATE) - 1 THEN investment_amount ELSE 0 END) - SUM(CASE WHEN YEAR(investment_date) = YEAR(CURRENT_DATE) - 2 THEN investment_amount ELSE 0 END)) * 100.0 / SUM(CASE WHEN YEAR(investment_date) = YEAR(CURRENT_DATE) - 2 THEN investment_amount ELSE 0 END) as yoy_growth FROM network_investments WHERE region = 'Ontario' AND YEAR(investment_date) >= YEAR(CURRENT_DATE) - 2;\n",
            "Generated Answer:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate exact match accuracy for 300 random samples from test dataset"
      ],
      "metadata": {
        "id": "FbkXjRFh_HB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import sample\n",
        "import re\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm # Import tqdm for a progress bar\n",
        "import time # Import the time module\n",
        "\n",
        "# Select Sample size\n",
        "random_indices = sample(range(len(dataset[\"test\"])), 300)\n",
        "\n",
        "# 1. Prepare the list of prompts and corresponding metadata (original answers, context, user query)\n",
        "prompts = []\n",
        "metadata = [] # To store the original data needed for evaluation\n",
        "\n",
        "# Iterate through the selected random samples to prepare the inputs\n",
        "for i in random_indices:\n",
        "    test_sample = dataset[\"test\"][i]\n",
        "    # Apply chat template for the prompt\n",
        "    prompt = pipe.tokenizer.apply_chat_template(\n",
        "        test_sample[\"messages\"][:2],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "    prompts.append(prompt)\n",
        "\n",
        "    # Extract metadata for later comparison\n",
        "    context = re.search(r'<SCHEMA>\\n(.*?)\\n</SCHEMA>', test_sample['messages'][0]['content'], re.DOTALL).group(1).strip()\n",
        "    user_query = re.search(r'<USER_QUERY>\\n(.*?)\\n</USER_QUERY>', test_sample['messages'][0]['content'], re.DOTALL).group(1).strip()\n",
        "    original_answer = test_sample['messages'][1]['content']\n",
        "\n",
        "    metadata.append({\n",
        "        \"Context\": context,\n",
        "        \"User Query\": user_query,\n",
        "        \"Original SQL\": original_answer\n",
        "    })\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# 2. Run the pipeline on ALL prompts simultaneously (The key transformation)\n",
        "# The pipeline will automatically batch and parallelize the GPU calls.\n",
        "# Note: You might need to adjust 'batch_size' depending on your GPU memory.\n",
        "# The `stop_token_ids` should be passed as a list of tokens/sequences to the pipeline call.\n",
        "# This assumes `stop_token_ids` is a list of integers (token IDs).\n",
        "# The pipeline is smart enough to handle a list of inputs.\n",
        "outputs = pipe(\n",
        "    prompts,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=False,\n",
        "    temperature=0.1,\n",
        "    top_k=50,\n",
        "    top_p=0.1,\n",
        "    eos_token_id=stop_token_ids, # This argument name is correct for the batched pipeline call\n",
        "    # You can also use \"stopping_criteria\" if you need more complex stopping logic\n",
        "    # disable_compile=True, # Keep this if you had issues with compilation\n",
        "    batch_size=32 # Set an appropriate batch size (e.g., 8, 16, 32)\n",
        ")\n",
        "\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the processing time\n",
        "processing_time = end_time - start_time\n",
        "\n",
        "# 3. Process the batched results\n",
        "evaluation_data = []\n",
        "exact_matches = 0\n",
        "\n",
        "# Iterate through the generated outputs and their corresponding original metadata\n",
        "for output, meta in zip(tqdm(outputs, desc=\"Processing Outputs\"), metadata):\n",
        "    # Extract the generated query from the model output\n",
        "    generated_text = output[0]['generated_text']\n",
        "    parts = generated_text.split(\"<start_of_turn>model\\n\")\n",
        "    if len(parts) > 1:\n",
        "        model_output_part = parts[1]\n",
        "        generated_query_parts = model_output_part.split(\"<end_of_turn>\")\n",
        "        generated_query = generated_query_parts[0].strip() if generated_query_parts else \"Could not extract SQL query\"\n",
        "    else:\n",
        "        generated_query = \"Could not extract SQL query\"\n",
        "\n",
        "    # Check for exact match using the extracted metadata\n",
        "    original_answer = meta[\"Original SQL\"]\n",
        "    if generated_query == original_answer:\n",
        "        exact_matches += 1\n",
        "\n",
        "    # Append the data, combining metadata and generated result\n",
        "    evaluation_data.append({\n",
        "        \"Context\": meta[\"Context\"],\n",
        "        \"User Query\": meta[\"User Query\"],\n",
        "        \"Original SQL\": original_answer,\n",
        "        \"Generated SQL\": generated_query\n",
        "    })\n",
        "\n",
        "# Calculate exact match accuracy\n",
        "accuracy = (exact_matches / len(random_indices)) * 100\n",
        "\n",
        "# Convert the list to a pandas DataFrame\n",
        "evaluation_df = pd.DataFrame(evaluation_data)\n",
        "\n",
        "# Display the evaluation table and accuracy\n",
        "display(evaluation_df)\n",
        "print(f\"\\nExact Match Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Print the processing time\n",
        "print(f\"\\nProcessing Time for {len(random_indices)} samples: {processing_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "616628fb7ca54a8c91a1606ac2098911",
            "719bbb4ce2d64161a78c488e937ad74a",
            "14910447b8de4b52a2e7c0f7443116af",
            "dcde37c711484139b8c0014418a90d8f",
            "8254aac9c5844057862c03bc37f85930",
            "942843e9a90e45268a11d69c28538d79",
            "9a99a930a6f646a5b0cf06af410ca44c",
            "6c5b414c6c334fbaabb59e045624c0e3",
            "d41904a3f93b4f598fa2f0b708f2ae21",
            "6a5da079b33d4fd9a719f0b72284c84a",
            "58b659f92da04da59bcc6357f6939e53"
          ]
        },
        "id": "uoYcJ0vSG-Z1",
        "outputId": "58271d11-2f89-4da3-af5e-9ebead7c581d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Outputs:   0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "616628fb7ca54a8c91a1606ac2098911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                               Context  \\\n",
              "0    CREATE TABLE EuroBikeSharing (id INT, city VAR...   \n",
              "1    CREATE TABLE Textiles (brand VARCHAR(20), fabr...   \n",
              "2    CREATE TABLE university_faculty (id INT, gende...   \n",
              "3    CREATE TABLE EmploymentStats (state VARCHAR(25...   \n",
              "4    CREATE TABLE CropData (id INT, Crop VARCHAR(25...   \n",
              "..                                                 ...   \n",
              "295  CREATE TABLE unions (id INT, name VARCHAR(20))...   \n",
              "296  CREATE TABLE CityVisitors (id INT, city VARCHA...   \n",
              "297  CREATE TABLE Funding (id INT, project_id INT, ...   \n",
              "298  CREATE TABLE Exhibitions(id INT, name VARCHAR(...   \n",
              "299  CREATE TABLE clean_energy_policy_trends (count...   \n",
              "\n",
              "                                            User Query  \\\n",
              "0    How many bike-sharing stations are there in Pa...   \n",
              "1    Show the total quantity of all sustainable fab...   \n",
              "2    What is the percentage of female faculty membe...   \n",
              "3    What is the employment rate for veterans in th...   \n",
              "4    What is the average nitrogen level for each cr...   \n",
              "..                                                 ...   \n",
              "295       How many unions are present in the database?   \n",
              "296  Which cities had more than 100,000 visitors in...   \n",
              "297  Show funding trends for renewable energy proje...   \n",
              "298  What are the names of the exhibitions where Im...   \n",
              "299  What is the policy trend for renewable energy ...   \n",
              "\n",
              "                                          Original SQL  \\\n",
              "0    SELECT city, SUM(stations) FROM EuroBikeSharin...   \n",
              "1    SELECT brand, fabric_type, SUM(quantity) FROM ...   \n",
              "2    SELECT ROUND(100.0 * SUM(CASE WHEN gender = 'F...   \n",
              "3    SELECT veteran_employment_rate FROM Employment...   \n",
              "4    SELECT Crop, AVG(NitrogenLevel) as AvgNitrogen...   \n",
              "..                                                 ...   \n",
              "295           SELECT COUNT(DISTINCT name) FROM unions;   \n",
              "296  SELECT city, SUM(num_visitors) FROM CityVisito...   \n",
              "297  SELECT t.year, AVG(f.amount) as avg_funding_am...   \n",
              "298  SELECT Exhibitions.name FROM Exhibitions INNER...   \n",
              "299  SELECT adoption_rate FROM clean_energy_policy_...   \n",
              "\n",
              "                                         Generated SQL  \n",
              "0    SELECT city, SUM(stations) FROM EuroBikeSharin...  \n",
              "1    SELECT brand, fabric_type, SUM(quantity) FROM ...  \n",
              "2    SELECT ROUND(100.0 * SUM(CASE WHEN gender = 'F...  \n",
              "3    SELECT veteran_employment_rate FROM Employment...  \n",
              "4    SELECT Crop, AVG(NitrogenLevel) as AvgNitrogen...  \n",
              "..                                                 ...  \n",
              "295           SELECT COUNT(DISTINCT name) FROM unions;  \n",
              "296  SELECT city, SUM(num_visitors) FROM CityVisito...  \n",
              "297  SELECT t.year, AVG(f.amount) as avg_funding_am...  \n",
              "298  SELECT Exhibitions.name FROM Exhibitions INNER...  \n",
              "299  SELECT adoption_rate FROM clean_energy_policy_...  \n",
              "\n",
              "[300 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f88e40b0-700d-4547-bf91-76e8475fc6e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context</th>\n",
              "      <th>User Query</th>\n",
              "      <th>Original SQL</th>\n",
              "      <th>Generated SQL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CREATE TABLE EuroBikeSharing (id INT, city VAR...</td>\n",
              "      <td>How many bike-sharing stations are there in Pa...</td>\n",
              "      <td>SELECT city, SUM(stations) FROM EuroBikeSharin...</td>\n",
              "      <td>SELECT city, SUM(stations) FROM EuroBikeSharin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CREATE TABLE Textiles (brand VARCHAR(20), fabr...</td>\n",
              "      <td>Show the total quantity of all sustainable fab...</td>\n",
              "      <td>SELECT brand, fabric_type, SUM(quantity) FROM ...</td>\n",
              "      <td>SELECT brand, fabric_type, SUM(quantity) FROM ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CREATE TABLE university_faculty (id INT, gende...</td>\n",
              "      <td>What is the percentage of female faculty membe...</td>\n",
              "      <td>SELECT ROUND(100.0 * SUM(CASE WHEN gender = 'F...</td>\n",
              "      <td>SELECT ROUND(100.0 * SUM(CASE WHEN gender = 'F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CREATE TABLE EmploymentStats (state VARCHAR(25...</td>\n",
              "      <td>What is the employment rate for veterans in th...</td>\n",
              "      <td>SELECT veteran_employment_rate FROM Employment...</td>\n",
              "      <td>SELECT veteran_employment_rate FROM Employment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CREATE TABLE CropData (id INT, Crop VARCHAR(25...</td>\n",
              "      <td>What is the average nitrogen level for each cr...</td>\n",
              "      <td>SELECT Crop, AVG(NitrogenLevel) as AvgNitrogen...</td>\n",
              "      <td>SELECT Crop, AVG(NitrogenLevel) as AvgNitrogen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>CREATE TABLE unions (id INT, name VARCHAR(20))...</td>\n",
              "      <td>How many unions are present in the database?</td>\n",
              "      <td>SELECT COUNT(DISTINCT name) FROM unions;</td>\n",
              "      <td>SELECT COUNT(DISTINCT name) FROM unions;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>CREATE TABLE CityVisitors (id INT, city VARCHA...</td>\n",
              "      <td>Which cities had more than 100,000 visitors in...</td>\n",
              "      <td>SELECT city, SUM(num_visitors) FROM CityVisito...</td>\n",
              "      <td>SELECT city, SUM(num_visitors) FROM CityVisito...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>CREATE TABLE Funding (id INT, project_id INT, ...</td>\n",
              "      <td>Show funding trends for renewable energy proje...</td>\n",
              "      <td>SELECT t.year, AVG(f.amount) as avg_funding_am...</td>\n",
              "      <td>SELECT t.year, AVG(f.amount) as avg_funding_am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>CREATE TABLE Exhibitions(id INT, name VARCHAR(...</td>\n",
              "      <td>What are the names of the exhibitions where Im...</td>\n",
              "      <td>SELECT Exhibitions.name FROM Exhibitions INNER...</td>\n",
              "      <td>SELECT Exhibitions.name FROM Exhibitions INNER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>CREATE TABLE clean_energy_policy_trends (count...</td>\n",
              "      <td>What is the policy trend for renewable energy ...</td>\n",
              "      <td>SELECT adoption_rate FROM clean_energy_policy_...</td>\n",
              "      <td>SELECT adoption_rate FROM clean_energy_policy_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f88e40b0-700d-4547-bf91-76e8475fc6e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f88e40b0-700d-4547-bf91-76e8475fc6e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f88e40b0-700d-4547-bf91-76e8475fc6e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-51a5e9ef-cf56-4f22-830f-14ab8c250c25\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51a5e9ef-cf56-4f22-830f-14ab8c250c25')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-51a5e9ef-cf56-4f22-830f-14ab8c250c25 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_94438b52-21dd-4299-ab90-ed22a80c9e39\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('evaluation_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_94438b52-21dd-4299-ab90-ed22a80c9e39 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('evaluation_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "evaluation_df",
              "summary": "{\n  \"name\": \"evaluation_df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"CREATE TABLE sf_crime_stats (id INT, crime_type TEXT, crime_date DATE); INSERT INTO sf_crime_stats (id, crime_type, crime_date) VALUES  (1, 'Theft', '2022-01-01'), (2, 'Vandalism', '2022-02-01'), (3, 'Assault', '2022-03-01');\",\n          \"CREATE TABLE marine_species (name VARCHAR(255), region VARCHAR(255), threatened_by_climate_change BOOLEAN); INSERT INTO marine_species (name, region, threatened_by_climate_change) VALUES ('Species 1', 'Indian Ocean', TRUE); INSERT INTO marine_species (name, region, threatened_by_climate_change) VALUES ('Species 2', 'Atlantic', FALSE);\",\n          \"CREATE TABLE open_pedagogy (course_id INT, district VARCHAR(50), course_type VARCHAR(50)); INSERT INTO open_pedagogy (course_id, district, course_type) VALUES (1001, 'Urban School District', 'Traditional'), (1002, 'Rural School District', 'Open'), (1003, 'Urban School District', 'Traditional');\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"User Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"What is the total number of thefts in San Francisco in 2022?\",\n          \"What is the total number of marine species in the Indian Ocean that are threatened by climate change?\",\n          \"What is the count of open pedagogy courses offered in 'Rural School District'?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Original SQL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"SELECT COUNT(*) FROM sf_crime_stats WHERE crime_type = 'Theft' AND YEAR(crime_date) = 2022;\",\n          \"SELECT COUNT(*) FROM marine_species WHERE region = 'Indian Ocean' AND threatened_by_climate_change = TRUE;\",\n          \"SELECT COUNT(*) FROM open_pedagogy WHERE district = 'Rural School District' AND course_type = 'Open';\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generated SQL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"SELECT COUNT(*) FROM sf_crime_stats WHERE crime_type = 'Theft' AND YEAR(crime_date) = 2022;\",\n          \"SELECT COUNT(*) FROM marine_species WHERE region = 'Indian Ocean' AND threatened_by_climate_change = TRUE;\",\n          \"SELECT COUNT(*) FROM open_pedagogy WHERE district = 'Rural School District' AND course_type = 'Open';\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exact Match Accuracy: 100.00%\n",
            "\n",
            "Processing Time for 300 samples: 250.34 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extra\n",
        "Download Adapters files & trained folder"
      ],
      "metadata": {
        "id": "Tb2rysoPJXp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /tmp/gemma-text-to-sql.zip gemma-text-to-sql\n",
        "from google.colab import files\n",
        "files.download('/tmp/gemma-text-to-sql.zip')"
      ],
      "metadata": {
        "id": "j3_5XtKAutyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
