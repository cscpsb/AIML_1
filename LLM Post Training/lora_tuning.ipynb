{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cscpsb/AIML_1/blob/main/LLM%20Post%20Training/lora_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "IMdQa9lRMBJf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDEExiAk4fLb"
      },
      "source": [
        "# Fine-tune Gemma in Keras using LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyhHCMfoRZ_v"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set environment variables"
      ],
      "metadata": {
        "id": "6CEjyL8sTVYR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0_EdOg9DPK6Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Note: `userdata.get` is a Colab API. If you're not using Colab, set the env\n",
        "# vars as appropriate for your system.\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuEUAKJW1QkQ"
      },
      "source": [
        "#### Install Keras python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1eeBtYqJsZPG"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U keras-hub\n",
        "!pip install  -q -U keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGLS-l5TxIR4"
      },
      "source": [
        "#### Select a backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yn5uy8X8sdD0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
        "# Avoid memory fragmentation on JAX backend.\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZs8XXqUKRmi"
      },
      "source": [
        "#### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FYHyPUA9hKTf"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RCE3fdGhDE5"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vz5zLEyLstfn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "10639e42-f5ba-4650-f082-c3bf519c4d14",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma3_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma3_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (\u001b[38;5;33mGemma3Tokenizer\u001b[0m)                            │                      Vocab size: \u001b[38;5;34m262,144\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Tokenizer</span>)                            │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma3_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma3_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)        │     \u001b[38;5;34m999,885,952\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemma3Backbone\u001b[0m)              │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)      │     \u001b[38;5;34m301,989,888\u001b[0m │ gemma3_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">999,885,952</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Backbone</span>)              │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">301,989,888</span> │ gemma3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m999,885,952\u001b[0m (3.72 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">999,885,952</span> (3.72 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m999,885,952\u001b[0m (3.72 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">999,885,952</span> (3.72 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "gemma_lm = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "gemma_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_L6A5J-1QgC"
      },
      "source": [
        "## Inference before fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVLXadptyo34"
      },
      "source": [
        "#### Europe trip prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZwQz3xxxKciD",
        "outputId": "99b3f217-f09b-4fb2-a415-061e8da72556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "What should I do on a trip to Europe?\n",
            "\n",
            "Response:\n",
            "Europe offers a huge and diverse range of experiences! To help you plan the perfect trip, here's a breakdown of suggestions based on different interests and budgets:\n",
            "\n",
            "**1. Popular Destinations (Good for First-Timers):**\n",
            "\n",
            "*   **Paris:** Iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre Dame Cathedral. Romantic atmosphere, world-class cuisine.\n",
            "*   **Rome:** Ancient history, stunning architecture (Colosseum, Roman Forum), delicious pasta and pizza.\n",
            "*   **London:** Royal history, vibrant theater scene, museums galore (British Museum, National Gallery).\n",
            "*   **Barcelona:** Unique architecture (Gaudí's Sagrada Familia), beaches, lively nightlife.\n",
            "*   **Amsterdam:** Canals, museums (Rijksmuseum, Van Gogh Museum), charming architecture, cycling culture.\n",
            "\n",
            "**2. Budget-Friendly Options:**\n",
            "\n",
            "*   **Portugal:** Affordable cost of living, beautiful coastline, delicious seafood, charming towns.\n",
            "*   **Czech Republic:** Historic cities, beer gardens, affordable accommodation.\n",
            "*   **Hungary:** Thermal baths, vibrant culture, delicious food (goulash).\n",
            "*   **Poland\n"
          ]
        }
      ],
      "source": [
        "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "\n",
        "prompt = template.format(\n",
        "    instruction=\"What should I do on a trip to Europe?\",\n",
        "    response=\"\",\n",
        ")\n",
        "sampler = keras_hub.samplers.TopKSampler(k=5, seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ74Zz_S0iVv"
      },
      "source": [
        "###  Photosynthesis prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lorJMbsusgoo",
        "outputId": "4a09be61-1823-43cb-b1df-445f1c152114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "Explain the process of photosynthesis in a way that a child could understand.\n",
            "\n",
            "Response:\n",
            "Okay, imagine you're a plant! Plants are like little food factories.\n",
            "\n",
            "They need sunlight, like you need sunshine to play outside. That’s how they get their energy.\n",
            "\n",
            "Then, they drink water from the ground through their roots, just like you drink water with a straw.\n",
            "\n",
            "Plants also breathe in a gas called carbon dioxide, which is what we breathe *out*.  It's like a little ingredient for their food.\n",
            "\n",
            "Now, here’s the cool part – the plant uses the sunlight energy to mix the water and carbon dioxide. It makes sugar (which is their food!) and oxygen.\n",
            "\n",
            "So, plants are really amazing because they make their own food and give us the air we need to breathe!\n",
            "\n",
            "Does that make sense?\n",
            "\n",
            "---\n",
            "\n",
            "**Explanation of why this is a good response for a child:**\n",
            "\n",
            "* **Relatable Analogy:** Using the analogy of a plant being a \"food factory\" makes it easy to understand. Children are more likely to connect with this.\n",
            "* **Simple Language:** Avoids complicated scientific terms and uses straightforward language.\n",
            "* **Key Steps Explained:** It breaks down the\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*try_max length change*"
      ],
      "metadata": {
        "id": "88ZdkfvtIKiG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "outputId": "e636cf4c-c45e-4ad7-9d97-28f6c9a6f79d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SMG343Z4lwi",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "Explain the process of photosynthesis in a way that a child could understand.\n",
            "\n",
            "Response:\n",
            "Imagine plants are like little chefs! They use sunshine, water, and air to make their food.\n",
            "\n",
            "First, they grab water from the ground with their roots, like a straw!\n",
            "\n",
            "Then, they breathe in air, just like we do, but they take in a special kind of air called carbon dioxide.\n",
            "\n",
            "Next, the sunshine shines down and gives them energy to cook everything together\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt7Nr6a7tItO"
      },
      "source": [
        "## LoRA fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T7xe_jzslv4"
      },
      "source": [
        "#### Load dataset\n",
        "[Databricks Dolly 15k dataset](https://huggingface.co/datasets/databricks/databricks-dolly-15k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xRaNCPUXKoa7",
        "outputId": "ed155db0-c9ac-4e23-dc1b-1872af857e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-27 15:05:16--  https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.109.102, 18.238.109.92, 18.238.109.52, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.109.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64358e2179c45fcf1ada09f4/63c4dabe683d7254493568d2d3995c0e51abc8528ef3b4936497c538cb501e93?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251027%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251027T150516Z&X-Amz-Expires=3600&X-Amz-Signature=5987d39c75ce96b1d15f3fc8d391547f942be3732e871a68b1f7beb11f073ca7&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&x-id=GetObject&Expires=1761581116&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTU4MTExNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDM1OGUyMTc5YzQ1ZmNmMWFkYTA5ZjQvNjNjNGRhYmU2ODNkNzI1NDQ5MzU2OGQyZDM5OTVjMGU1MWFiYzg1MjhlZjNiNDkzNjQ5N2M1MzhjYjUwMWU5MyoifV19&Signature=JdYYDAAMR5UlVBjH%7EuMs7UqL90mPBjmumc5FPRbhlmwlMxfX-b9X5TRHwV6FaKxirt4oupepIWK5Ud%7EiLeW4HmOnha7wh0lzxLhQ1b7tFKVdUDl2TRNaf9UsqVhvXBkVsuuQ4pCxTQz-TjK6D03bKGXyKu9a1uVB7OfcrzAqhq4KsRwPoazx68YjCDlZv5TS0o7v5VS2rUuG-XpqogQdHSy56QltYJQMXnnA5SBTjv2KrQWB8plm-wUMECPrIGKvV3SZa%7E0wmLUZVaUPrn%7EopA4wwFNwyR7NL0dhZG3p1LC1ca8FKk%7Eeyh8rRoPL0Sb01sLw6irV5iiV3Q-4XIUHQw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-10-27 15:05:16--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64358e2179c45fcf1ada09f4/63c4dabe683d7254493568d2d3995c0e51abc8528ef3b4936497c538cb501e93?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251027%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251027T150516Z&X-Amz-Expires=3600&X-Amz-Signature=5987d39c75ce96b1d15f3fc8d391547f942be3732e871a68b1f7beb11f073ca7&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&x-id=GetObject&Expires=1761581116&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTU4MTExNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDM1OGUyMTc5YzQ1ZmNmMWFkYTA5ZjQvNjNjNGRhYmU2ODNkNzI1NDQ5MzU2OGQyZDM5OTVjMGU1MWFiYzg1MjhlZjNiNDkzNjQ5N2M1MzhjYjUwMWU5MyoifV19&Signature=JdYYDAAMR5UlVBjH%7EuMs7UqL90mPBjmumc5FPRbhlmwlMxfX-b9X5TRHwV6FaKxirt4oupepIWK5Ud%7EiLeW4HmOnha7wh0lzxLhQ1b7tFKVdUDl2TRNaf9UsqVhvXBkVsuuQ4pCxTQz-TjK6D03bKGXyKu9a1uVB7OfcrzAqhq4KsRwPoazx68YjCDlZv5TS0o7v5VS2rUuG-XpqogQdHSy56QltYJQMXnnA5SBTjv2KrQWB8plm-wUMECPrIGKvV3SZa%7E0wmLUZVaUPrn%7EopA4wwFNwyR7NL0dhZG3p1LC1ca8FKk%7Eeyh8rRoPL0Sb01sLw6irV5iiV3Q-4XIUHQw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 99.84.215.118, 99.84.215.107, 99.84.215.77, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|99.84.215.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13085339 (12M)\n",
            "Saving to: ‘databricks-dolly-15k.jsonl’\n",
            "\n",
            "databricks-dolly-15 100%[===================>]  12.48M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-10-27 15:05:16 (83.6 MB/s) - ‘databricks-dolly-15k.jsonl’ saved [13085339/13085339]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O databricks-dolly-15k.jsonl https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45UpBDfBgf0I"
      },
      "source": [
        "#### Format tuning data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZiS-KU9osh_N"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "prompts = []\n",
        "responses = []\n",
        "line_count = 0\n",
        "\n",
        "with open(\"databricks-dolly-15k.jsonl\") as file:\n",
        "    for line in file:\n",
        "        if line_count >= 1000:\n",
        "            break  # Limit the training examples, to reduce execution time.\n",
        "\n",
        "        examples = json.loads(line)\n",
        "        # Filter out examples with context, to keep it simple.\n",
        "        if examples[\"context\"]:\n",
        "            continue\n",
        "        # Format data into prompts and response lists.\n",
        "        prompts.append(examples[\"instruction\"])\n",
        "        responses.append(examples[\"response\"])\n",
        "\n",
        "        line_count += 1\n",
        "\n",
        "data = {\n",
        "    \"prompts\": prompts,\n",
        "    \"responses\": responses\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBLW5hiGj31i"
      },
      "source": [
        "#### Configure LoRA tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RCucu6oHz53G"
      },
      "outputs": [],
      "source": [
        "# Enable LoRA for the model and set the LoRA rank.\n",
        "gemma_lm.backbone.enable_lora(rank=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlMLp_NVbRoQ"
      },
      "source": [
        "Check the model summary after setting the LoRA rank. Notice that enabling LoRA reduces the number of trainable parameters significantly compared to the total number of parameters in the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KqYyS0gm6pNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1908d5b0-d208-419c-ed46-90a696398b35"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma3_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma3_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (\u001b[38;5;33mGemma3Tokenizer\u001b[0m)                            │                      Vocab size: \u001b[38;5;34m262,144\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Tokenizer</span>)                            │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma3_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma3_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)        │   \u001b[38;5;34m1,000,538,240\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemma3Backbone\u001b[0m)              │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)      │     \u001b[38;5;34m301,989,888\u001b[0m │ gemma3_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,538,240</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Backbone</span>)              │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">301,989,888</span> │ gemma3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,000,538,240\u001b[0m (3.73 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,538,240</span> (3.73 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m652,288\u001b[0m (2.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">652,288</span> (2.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m999,885,952\u001b[0m (3.72 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">999,885,952</span> (3.72 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "gemma_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQQ47kcdpbZ9"
      },
      "source": [
        "Configure the rest of the fine-tuning settings, including the preprocessor settings, optimizer, number of tuning epochs, and batch size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p9sBNH8SAjgB"
      },
      "outputs": [],
      "source": [
        "# Limit the input sequence length to 256 (to control memory usage).\n",
        "gemma_lm.preprocessor.sequence_length = 256\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "gemma_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA0ozGC66tk1"
      },
      "source": [
        "#### Run the fine-tune process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_Peq7TnLtHse",
        "outputId": "f3198b81-1f45-4adb-c143-627610769336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 368ms/step - loss: 0.7437 - sparse_categorical_accuracy: 0.4937\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7957096ac230>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "gemma_lm.fit(data, epochs=1, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx3m8f1dB7nk"
      },
      "source": [
        "#### Mixed precision fine-tuning on NVIDIA GPUs (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T0lHxEDX03gp"
      },
      "outputs": [],
      "source": [
        "# Uncomment the line below if you want to enable mixed precision training on GPUs\n",
        "# keras.mixed_precision.set_global_policy('mixed_bfloat16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yd-1cNw1dTn"
      },
      "source": [
        "## Inference after fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H55JYJ1a1Kos"
      },
      "source": [
        "##### Europe trip prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y7cDJHy8WfCB",
        "outputId": "fd6ee42d-65cd-450e-e245-6bbaead995ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "What should I do on a trip to Europe?\n",
            "\n",
            "Response:\n",
            "Europe is a fantastic and diverse destination with many different things to do on a trip! Here are some suggestions:\n",
            "1. Visit historical sites: Visit the Colosseum, the Roman Forum, and the Pantheon in Rome.\n",
            "2. Visit the Eiffel Tower in Paris.\n",
            "3. Visit the Louvre Museum in Paris.\n",
            "4. Visit the British Museum in London.\n",
            "5. Visit the Brandenburg Gate in Berlin.\n",
            "6. Visit the Vatican in Rome.\n",
            "7. Visit the Spanish Steps in Rome.\n",
            "8. Visit the Tower of London in London.\n",
            "9. Visit the canals of Venice.\n",
            "10. Visit the canals ofAmsterdam.\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"What should I do on a trip to Europe?\",\n",
        "    response=\"\",\n",
        ")\n",
        "sampler = keras_hub.samplers.TopKSampler(k=5, seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7nVd8Mi1Yta"
      },
      "source": [
        "#### Photosynthesis prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X-2sYl2jqwl7",
        "outputId": "b8f20553-6b94-4c55-e260-e24c4f571bb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "Explain the process of photosynthesis in a way that a child could understand.\n",
            "\n",
            "Response:\n",
            "Imagine plants are like tiny chefs! They use sunlight as their energy source, like turning on the oven. They also take in water through their roots, like adding ingredients to a recipe. They take in carbon dioxide (a gas) from the air, like another ingredient. Then, inside their leaves, they use the sunlight, water, and carbon dioxide to make sugar(food) and oxygen. The sugar helps them grow, and the oxygen that they release is what we breathe! So, plants are really good at making food and giving us clean air!\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After gemma_lm.fit(...) finishes\n",
        "gemma_lm.save_weights(\"gemma_lora_adapters.weightsv1.h5\")"
      ],
      "metadata": {
        "id": "5O-8hR9EOrDH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8kFG12l0mVe"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Experiment with fine-tune parameteres\n",
        "\n",
        "Experiment with:\n",
        "\n",
        "1. Increasing the size of the fine-tuning dataset\n",
        "2. Training for more steps (epochs)\n",
        "3. Setting a higher LoRA rank\n",
        "4. Modifying the hyperparameter values such as `learning_rate` and `weight_decay`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqn89qsz9Mus"
      },
      "source": [
        "### E1 : Rank 4 to 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z2m2YQa9Muv"
      },
      "source": [
        "#### Configure LoRA tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lS4ySEFw9Muv"
      },
      "outputs": [],
      "source": [
        "gemma_lm = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "# You can change the rank value below to experiment with different ranks.\n",
        "gemma_lm.backbone.enable_lora(rank=8) # Changed rank from 4 to 8 as an example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEh7Gxop9Muw"
      },
      "source": [
        "Configure the rest of the fine-tuning settings, including the preprocessor settings, optimizer, number of tuning epochs, and batch size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nEv0jkqF9Muw"
      },
      "outputs": [],
      "source": [
        "# Limit the input sequence length to 256 (to control memory usage).\n",
        "gemma_lm.preprocessor.sequence_length = 256\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "gemma_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG9yA6Fb9Mux"
      },
      "source": [
        "#### Run the fine-tune process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "outputId": "be8458e1-1e3b-488d-f437-2472e27c60b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR33CG2d9Mux"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 365ms/step - loss: 0.7282 - sparse_categorical_accuracy: 0.4965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7955f04797f0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "gemma_lm.fit(data, epochs=1, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save adapter weights file in working directory (Optional)"
      ],
      "metadata": {
        "id": "HZF7e0x7QUVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "\n",
        "FILE_PATH = \"gemma_lora_adaptersv2.weights.h5\"\n",
        "\n",
        "print(f\"Starting to save adapter weights to: {FILE_PATH}...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# 1. Keras Save Operation\n",
        "gemma_lm.save_weights(FILE_PATH)\n",
        "\n",
        "end_time = time.time()\n",
        "time_taken = end_time - start_time\n",
        "print(\"Save complete! ✅\")\n",
        "\n",
        "# 2. File Size and Progress Output\n",
        "file_size_bytes = os.path.getsize(FILE_PATH)\n",
        "file_size_mb = file_size_bytes / (1024 * 1024)\n",
        "\n",
        "print(f\"Total time taken to save: **{time_taken:.2f} seconds**\")\n",
        "print(f\"Final adapter file size: **{file_size_mb:.2f} MB**\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxMwl0UiQTov",
        "outputId": "b0c6ce3e-97e9-4940-84c3-30d6157fb729"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to save adapter weights to: gemma_lora_adaptersv2.weights.h5...\n",
            "Save complete! ✅\n",
            "Total time taken to save: **311.92 seconds**\n",
            "Final adapter file size: **3825.36 MB**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEdNLusl9T9z"
      },
      "source": [
        "#### Inference after fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRUM4rBY9T90"
      },
      "source": [
        "##### Europe trip prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "outputId": "531e40c2-567d-428d-d797-9690880df538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlwWXn5U9T90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "What should I do on a trip to Europe?\n",
            "\n",
            "Response:\n",
            "Europe is a fantastic and diverse continent to travel in, and there is so much to do. Here's a breakdown of what to do on your trip to Europe, broken down into categories:\n",
            "1.  **Cities and Landmarks:**\n",
            "    *   Paris: Visit the Eiffel Tower, the Louvre Museum, Notre Dame Cathedral, and the Champs-Élysées.\n",
            "    *   Rome: Visit the Colosseum, the Roman Forum, Vatican City and the Pantheon.\n",
            "    *   London: See the London Eye, Buckingham Palace, the Tower of London and the British Museum.\n",
            "    *   Prague: Visit Charles Bridge, Prague Castle, and Old Town Square.\n",
            "2.  **Historical and Cultural Sites:**\n",
            "    *   Berlin: Visit the Brandenburg Gate and the Reichstag, and see many museums and historical sites.\n",
            "    *   Athens: Visit the Acropolis and the Parthenon\n",
            "    *   Istanbul: Visit the Hagia Sophia and Blue Mosque.\n",
            "3.\n"
          ]
        }
      ],
      "source": [
        "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "\n",
        "prompt = template.format(\n",
        "    instruction=\"What should I do on a trip to Europe?\",\n",
        "    response=\"\",\n",
        ")\n",
        "sampler = keras_hub.samplers.TopKSampler(k=5, seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRTftuVS9T90"
      },
      "source": [
        "The model now provides a shorter response to a question about visiting Europe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PhCfAE89T91"
      },
      "source": [
        "##### Photosynthesis prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "outputId": "a1c5f213-8c56-4340-b119-67d516bbf33a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOVROa1v9T91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "Explain the process of photosynthesis in a way that a child could understand.\n",
            "\n",
            "Response:\n",
            "Imagine the Sun is like a giant lightbulb, shining light to plants. Plants like to eat sunlight, just like we eat food. Plants take in sunlight, water and the air we breathe in. They use the sunlight to make their own food. This process of making food is called photosynthesis. Photosynthesis is the name for this process, and it is how plants make their own food!\n",
            "\n",
            "<start_of_image>\n"
          ]
        }
      ],
      "source": [
        "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "\n",
        "prompt = template.format(\n",
        "    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E2 : ft dataset size change"
      ],
      "metadata": {
        "id": "I6mwaldiHK09"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HXsXGZPHE2_"
      },
      "source": [
        "#### Format tuning data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qyliEwjdHE3A"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "prompts = []\n",
        "responses = []\n",
        "line_count = 0\n",
        "\n",
        "with open(\"databricks-dolly-15k.jsonl\") as file:\n",
        "    for line in file:\n",
        "        if line_count >= 1500:\n",
        "            break  # Limit the training examples, to reduce execution time.\n",
        "\n",
        "        examples = json.loads(line)\n",
        "        # Filter out examples with context, to keep it simple.\n",
        "        if examples[\"context\"]:\n",
        "            continue\n",
        "        # Format data into prompts and response lists.\n",
        "        prompts.append(examples[\"instruction\"])\n",
        "        responses.append(examples[\"response\"])\n",
        "\n",
        "        line_count += 1\n",
        "\n",
        "data = {\n",
        "    \"prompts\": prompts,\n",
        "    \"responses\": responses\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmcdlEZTHiZS"
      },
      "source": [
        "#### Configure LoRA tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3Ns24Mm7HiZT"
      },
      "outputs": [],
      "source": [
        "gemma_lm = keras_hub.models.Gemma3CausalLM.from_preset(\"gemma3_instruct_1b\")\n",
        "# You can change the rank value below to experiment with different ranks.\n",
        "gemma_lm.backbone.enable_lora(rank=4) # Changed rank from 4 to 8 as an example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKCMvmXWHiZT"
      },
      "source": [
        "Configure the rest of the fine-tuning settings, including the preprocessor settings, optimizer, number of tuning epochs, and batch size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kHVlscmRHiZT"
      },
      "outputs": [],
      "source": [
        "# Limit the input sequence length to 256 (to control memory usage).\n",
        "gemma_lm.preprocessor.sequence_length = 256\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "gemma_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idwfhjxDHiZU"
      },
      "source": [
        "#### Run the fine-tune process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "outputId": "5fcf9544-966d-400d-bebe-beaa68767008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PcuYjQaHiZU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 318ms/step - loss: 0.7168 - sparse_categorical_accuracy: 0.4992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d9860146960>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "gemma_lm.fit(data, epochs=1, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save in Hugging Face Hub (Optional)"
      ],
      "metadata": {
        "id": "XBRbyEpjTL5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install the required library (if you haven't already)\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "# ---\n",
        "# NOTE: Before running the next step, you must have added your Hugging Face\n",
        "#       token as a secret named 'HF_TOKEN' in the Colab Secrets Panel (key icon on the left).\n",
        "# ---\n",
        "\n",
        "# 2. Access the secret and set it as an environment variable\n",
        "# The 'from google.colab import userdata' is the most secure way to handle secrets.\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the token from Colab Secrets and set it as an environment variable\n",
        "# for the huggingface_hub library to pick up automatically.\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "print(\"Hugging Face token securely loaded from Colab Secrets.\")\n",
        "\n",
        "# 3. Define the repository ID and push the model\n",
        "# Replace 'Your_HF_Username' with your actual Hugging Face username\n",
        "REPO_ID = \"Your_HF_Username/gemma-lora-adapter-keras\"\n",
        "\n",
        "print(f\"\\nStarting to push adapter weights to Hugging Face Hub: {REPO_ID}\")\n",
        "\n",
        "# This will automatically use the HF_TOKEN environment variable for authentication.\n",
        "# (Assuming gemma_lm is a model object that supports Keras's save_pretrained or similar HF integration)\n",
        "gemma_lm.save_pretrained(\n",
        "    REPO_ID,\n",
        "    push_to_hub=True\n",
        ")\n",
        "\n",
        "print(\"\\nPush to Hugging Face Hub complete! ✅\")"
      ],
      "metadata": {
        "id": "fKVx4u2TTRxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKBdBY1NHiZU"
      },
      "source": [
        "#### Inference after fine-tuning\n",
        "\n",
        "After fine-tuning, you should see changes in the responses when the tuned model is given the same prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcDZtGn5HiZU"
      },
      "source": [
        "##### Europe trip prompt\n",
        "\n",
        "Try the Europe trip prompt from earlier and note the differences in the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "outputId": "89db414f-3e35-47d9-ae21-674364f37fd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAnrfdX3HiZU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "What should I do on a trip to Europe?\n",
            "\n",
            "Response:\n",
            "Europe is a continent that offers a variety of attractions for travelers. Here are some things you can do in Europe:\n",
            "* Visit historical sites such as the Colosseum in Rome, the Eiffel Tower in Paris, and the Great Wall of China.\n",
            "* Visit the beaches in Greece and Italy.\n",
            "* Visit the mountains in Switzerland and Austria.\n",
            "*Visit the castles in Germany.\n",
            "*Visit the cities such as Berlin, Prague, and Vienna.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "\n",
        "prompt = template.format(\n",
        "    instruction=\"What should I do on a trip to Europe?\",\n",
        "    response=\"\",\n",
        ")\n",
        "sampler = keras_hub.samplers.TopKSampler(k=5, seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j3r1uXXHiZV"
      },
      "source": [
        "##### Photosynthesis prompt\n",
        "\n",
        "Try the photosynthesis explanation prompt from earlier and note the differences in the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "outputId": "590cb91f-1460-45e3-895c-0f7c86f8a2d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVtFBt1CHiZV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "Explain the process of photosynthesis in a way that a child could understand.\n",
            "\n",
            "Response:\n",
            "Photosynthesis is how plants make their own food! It is like a magic recipe where plants use sunlight, water, and air to make their own food (sugar) and release oxygen.\n",
            "1. Sunlight is like the energy that helps the plant make the sugar.\n",
            "2. Water from the ground comes in through the roots, like it’s a little juice for the plant.\n",
            "3. Air (specifically the carbon dioxide from the air) comes in through tiny holes on the leaves.\n",
            "4. Plants take these things in and put them together using sunlight energy in a process called photosynthesis.\n",
            "5.  Then they make sugar and the air we breathe out!\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SDEExiAk4fLb",
        "lyhHCMfoRZ_v",
        "6CEjyL8sTVYR",
        "CuEUAKJW1QkQ",
        "rGLS-l5TxIR4",
        "hZs8XXqUKRmi",
        "7RCE3fdGhDE5",
        "PVLXadptyo34",
        "YQ74Zz_S0iVv",
        "9T7xe_jzslv4",
        "45UpBDfBgf0I",
        "cBLW5hiGj31i",
        "OA0ozGC66tk1",
        "bx3m8f1dB7nk",
        "4yd-1cNw1dTn",
        "H55JYJ1a1Kos",
        "H7nVd8Mi1Yta",
        "I8kFG12l0mVe",
        "-Z2m2YQa9Muv",
        "yG9yA6Fb9Mux",
        "HZF7e0x7QUVQ",
        "1HXsXGZPHE2_",
        "QmcdlEZTHiZS",
        "idwfhjxDHiZU",
        "XBRbyEpjTL5I"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}