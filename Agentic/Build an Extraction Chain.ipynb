{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["CZdvxhzoM19U","twme4Q5xKshW"],"authorship_tag":"ABX9TyObUBKnAmW7+L0DjJnDeMxT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"CZdvxhzoM19U"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"4m4w5xAeqLCg","executionInfo":{"status":"ok","timestamp":1750683918714,"user_tz":-330,"elapsed":5701,"user":{"displayName":"CsCps","userId":"14620911368645062286"}}},"outputs":[],"source":["pip install --upgrade --quiet langchain-core"]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\"\n","os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('Smith2')"],"metadata":{"id":"_luMmXaHJp1K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The Schema"],"metadata":{"id":"twme4Q5xKshW"}},{"cell_type":"code","source":["from typing import Optional\n","\n","from pydantic import BaseModel, Field\n","\n","\n","class Person(BaseModel):\n","    \"\"\"Information about a person.\"\"\"\n","\n","    # ^ Doc-string for the entity Person.\n","    # This doc-string is sent to the LLM as the description of the schema Person,\n","    # and it can help to improve extraction results.\n","\n","    # Note that:\n","    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n","    # 2. Each field has a `description` -- this description is used by the LLM.\n","    # Having a good description can help improve extraction results.\n","    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n","    hair_color: Optional[str] = Field(\n","        default=None, description=\"The color of the person's hair if known\"\n","    )\n","    height_in_meters: Optional[str] = Field(\n","        default=None, description=\"Height measured in meters\"\n","    )"],"metadata":{"id":"G-3AUCfAKwUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The Extractor"],"metadata":{"id":"Zl_h4rscMw2f"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","# Define a custom prompt to provide instructions and any additional context.\n","# 1) You can add examples into the prompt template to improve extraction quality\n","# 2) Introduce additional parameters to take context into account (e.g., include metadata\n","#    about the document from which the text was extracted.)\n","prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are an expert extraction algorithm. \"\n","            \"Only extract relevant information from the text. \"\n","            \"If you do not know the value of an attribute asked to extract, \"\n","            \"return null for the attribute's value.\",\n","        ),\n","        # Please see the how-to about improving performance with\n","        # reference examples.\n","        # MessagesPlaceholder('examples'),\n","        (\"human\", \"{text}\"),\n","    ]\n",")"],"metadata":{"id":"QZDscbQRM8Z9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install -qU \"langchain[google-genai]\""],"metadata":{"collapsed":true,"id":"9WH7HytrNYp3","executionInfo":{"status":"ok","timestamp":1749887883634,"user_tz":-330,"elapsed":13872,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"473dc05c-d883-4540-e2b1-f1390e8b5cff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.4/1.4 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["#modified\n","from google.colab import userdata\n","import os\n","if not os.environ.get(\"GOOGLE_API_KEY\"):\n","  os.environ[\"GOOGLE_API_KEY\"] = userdata.get('gemini')\n","\n","from langchain.chat_models import init_chat_model\n","\n","llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"],"metadata":{"id":"tUqG0suuNwl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["structured_llm = llm.with_structured_output(schema=Person)"],"metadata":{"id":"3HJeIbLVOpt4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test\n","text = \"Alan Smith is 6 feet tall and has blond hair.\"\n","prompt = prompt_template.invoke({\"text\": text})\n","structured_llm.invoke(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKW9KScIOs0_","executionInfo":{"status":"ok","timestamp":1749887886754,"user_tz":-330,"elapsed":734,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"80a10772-5014-4872-fb58-dd4840430c62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Person(name='Alan Smith', hair_color='blond', height_in_meters='1.8288')"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Multiple Entities"],"metadata":{"id":"833_PmsHfj1n"}},{"cell_type":"code","source":["from typing import List, Optional\n","\n","from pydantic import BaseModel, Field\n","\n","\n","class Person(BaseModel):\n","    \"\"\"Information about a person.\"\"\"\n","\n","    # ^ Doc-string for the entity Person.\n","    # This doc-string is sent to the LLM as the description of the schema Person,\n","    # and it can help to improve extraction results.\n","\n","    # Note that:\n","    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n","    # 2. Each field has a `description` -- this description is used by the LLM.\n","    # Having a good description can help improve extraction results.\n","    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n","    hair_color: Optional[str] = Field(\n","        default=None, description=\"The color of the person's hair if known\"\n","    )\n","    height_in_meters: Optional[str] = Field(\n","        default=None, description=\"Height measured in meters\"\n","    )\n","\n","\n","class Data(BaseModel):\n","    \"\"\"Extracted data about people.\"\"\"\n","\n","    # Creates a model so that we can extract multiple entities.\n","    people: List[Person]"],"metadata":{"id":"ymMJbuBGfmIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["structured_llm2 = llm.with_structured_output(schema=Data)\n","text = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n","prompt = prompt_template.invoke({\"text\": text})\n","structured_llm2.invoke(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcmjqcK8f1ul","executionInfo":{"status":"ok","timestamp":1749888814659,"user_tz":-330,"elapsed":805,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"e25e8ed6-8149-4fb3-9130-de63951a4776"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(people=[Person(name='Jeff', hair_color='black', height_in_meters='1.8288'), Person(name='Anna', hair_color='black', height_in_meters=None)])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# Reference Examples"],"metadata":{"id":"DmUMugsSmXdZ"}},{"cell_type":"markdown","source":["### Few Shot Prompting"],"metadata":{"id":"LASmxlJgJw5l"}},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"user\", \"content\": \"2 ğŸ¦œ 2\"},\n","    {\"role\": \"assistant\", \"content\": \"4\"},\n","    {\"role\": \"user\", \"content\": \"2 ğŸ¦œ 3\"},\n","    {\"role\": \"assistant\", \"content\": \"5\"},\n","    {\"role\": \"user\", \"content\": \"3 ğŸ¦œ 4\"},\n","]\n","response = llm.invoke(messages)\n","print(response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UF-RrddngOkV","executionInfo":{"status":"ok","timestamp":1749888926601,"user_tz":-330,"elapsed":452,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"0973e0bf-2f42-46d8-ee37-0e350a64e5c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n"]}]},{"cell_type":"markdown","source":["Strucutured Output using **utility function** tool_example_to_message"],"metadata":{"id":"41ZfGz8UKiaW"}},{"cell_type":"code","source":["from langchain_core.utils.function_calling import tool_example_to_messages\n","\n","examples = [\n","    (\n","        \"The ocean is vast and blue. It's more than 20,000 feet deep.\",\n","        Data(people=[]),\n","    ),\n","    (\n","        \"Fiona traveled far from France to Spain.\",\n","        Data(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n","    ),\n","]\n","\n","\n","messages = []\n","\n","for txt, tool_call in examples:\n","    if tool_call.people:\n","        # This final message is optional for some providers\n","        ai_response = \"Detected people.\"\n","    else:\n","        ai_response = \"Detected no people.\"\n","    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfW1PYb9gmqt","executionInfo":{"status":"ok","timestamp":1749888956363,"user_tz":-330,"elapsed":40,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"8d5e5d5f-9934-409d-c678-8a04ada63ac7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-81328896>:23: LangChainBetaWarning: The function `tool_example_to_messages` is in beta. It is actively being worked on, so the API may change.\n","  messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))\n"]}]},{"cell_type":"code","source":["for message in messages:\n","    message.pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFiRNg5zgrCd","executionInfo":{"status":"ok","timestamp":1749888991873,"user_tz":-330,"elapsed":41,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"38f099a0-0fb2-4d19-b072-f51df58cf05b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","The ocean is vast and blue. It's more than 20,000 feet deep.\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  Data (ace2a258-907a-4870-add8-af0ea33e46ca)\n"," Call ID: ace2a258-907a-4870-add8-af0ea33e46ca\n","  Args:\n","    people: []\n","=================================\u001b[1m Tool Message \u001b[0m=================================\n","\n","You have correctly called this tool.\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Detected no people.\n","================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Fiona traveled far from France to Spain.\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  Data (4120f46d-6933-407e-aa40-054047d7e74a)\n"," Call ID: 4120f46d-6933-407e-aa40-054047d7e74a\n","  Args:\n","    people: [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]\n","=================================\u001b[1m Tool Message \u001b[0m=================================\n","\n","You have correctly called this tool.\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Detected people.\n"]}]},{"cell_type":"code","source":["message_no_extraction = {\n","    \"role\": \"user\",\n","    \"content\": \"The Andrew is tall, and Nima has only 1 nose.\",\n","}\n","structured_llm2 = llm.with_structured_output(schema=Data)\n","structured_llm2.invoke([message_no_extraction])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"onHDXYjpgzr9","executionInfo":{"status":"ok","timestamp":1749889266962,"user_tz":-330,"elapsed":634,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"bf71a463-6a88-4d30-c036-aad24f5d9552"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(people=[Person(name='Andrew', hair_color=None, height_in_meters='tall'), Person(name='Nima', hair_color=None, height_in_meters=None)])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["structured_llm2 = llm.with_structured_output(schema=Data)\n","structured_llm2.invoke(message + [message_no_extraction])"],"metadata":{"id":"MbpD7mq9_Srt"},"execution_count":null,"outputs":[]}]}