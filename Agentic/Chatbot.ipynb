{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["2PAfhg9A9YQd","eWew3daM_kYP","e0hLHmAvH_zs","YASb0Vp_Vd83","vXhyvm1ZVexG","BCwk-qcBVfA3"],"toc_visible":true,"authorship_tag":"ABX9TyN51CyeozsBLGqSrhx+8dvC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"2PAfhg9A9YQd"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"OTiulvLD9QqL","executionInfo":{"status":"ok","timestamp":1750764152492,"user_tz":-330,"elapsed":4557,"user":{"displayName":"CsCps","userId":"14620911368645062286"}}},"outputs":[],"source":["pip install langchain-core langgraph>0.2.27"]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\"\n","os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('Smith2')"],"metadata":{"id":"4u1Y4xdw9WgJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","### Quick Start"],"metadata":{"id":"eWew3daM_kYP"}},{"cell_type":"markdown","source":["#### LLM setup"],"metadata":{"id":"vC5-4tt_CSk-"}},{"cell_type":"code","source":["pip install -qU \"langchain[google-genai]\""],"metadata":{"id":"9D17dOJA_n0h","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","\n","# Retrieve the Gemini API key from Colab's user data\n","gemini_api_key = userdata.get('gemini')\n","\n","from langchain.chat_models import init_chat_model\n","\n","model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\",google_api_key=gemini_api_key)"],"metadata":{"id":"GESifik2BElp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["play around - It doesnot remember / Workaround = pass entire convo history"],"metadata":{"id":"wfOv0arlCoC4"}},{"cell_type":"code","source":["from langchain_core.messages import HumanMessage\n","\n","model.invoke([HumanMessage(content=\"Hi! I'm MKV. Donot respond in cliche\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LaPfnMrpBcKV","executionInfo":{"status":"ok","timestamp":1750684443391,"user_tz":-330,"elapsed":538,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"9adb0d37-f719-4059-c27d-6992eaa11101","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Understood, MKV. How can I assist you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--673fce01-2394-420c-bd92-366812eb74b2-0', usage_metadata={'input_tokens': 13, 'output_tokens': 13, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["model.invoke([HumanMessage(content=\"What's my name?\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scaeDA5AB4vs","executionInfo":{"status":"ok","timestamp":1750684488118,"user_tz":-330,"elapsed":564,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"33e652a6-0774-4121-e979-4e1a3e18bb6a","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"As a large language model, I don't have access to personal information about you. Therefore, I do not know your name.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--8b8f80c4-1e0f-42de-9160-8ff825bdfee4-0', usage_metadata={'input_tokens': 6, 'output_tokens': 28, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# @title\n","model.invoke([HumanMessage(content=\"Think harder, I have told you\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6fn_YuvB-t6","executionInfo":{"status":"ok","timestamp":1750684583903,"user_tz":-330,"elapsed":3092,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"6e106695-f283-404a-9c71-714cad3896e7","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Okay. You\\'ve told me to think harder. That implies I haven\\'t been thinking hard enough, or haven\\'t been thinking in the *right* way to satisfy your request.\\n\\nTo think harder, I need more information.  Specifically:\\n\\n*   **What was the original question or task?**  I need context to understand what I\\'m supposed to be \"thinking harder\" *about*.\\n*   **What was my previous response?** Knowing what I already said will help me identify the areas where I need to improve.\\n*   **What specific aspects of my previous response were inadequate?**  Was it the depth of the analysis, the breadth of the solution, the creativity of the approach, the accuracy of the information, or something else entirely?\\n*   **What are your expectations for a \"harder\" thought process?**  Are you looking for me to:\\n    *   Consider more variables?\\n    *   Explore more complex relationships?\\n    *   Generate more creative solutions?\\n    *   Provide more detailed explanations?\\n    *   Challenge assumptions?\\n    *   Synthesize information from multiple sources?\\n    *   Apply a specific framework or theory?\\n\\nWithout knowing the context, I can only offer general strategies for \"thinking harder,\" such as:\\n\\n*   **Breaking down the problem into smaller parts:** This can make a complex problem more manageable.\\n*   **Considering different perspectives:**  Imagine how someone with a different background or expertise might approach the problem.\\n*   **Challenging assumptions:**  Are there any underlying beliefs that might be limiting my thinking?\\n*   **Looking for analogies and metaphors:**  Can I relate the problem to something I already understand?\\n*   **Generating multiple possible solutions:**  Don\\'t settle for the first idea that comes to mind.\\n*   **Evaluating the pros and cons of each solution:**  Think critically about the potential consequences of each option.\\n*   **Seeking out additional information:**  Are there any resources that could help me better understand the problem?\\n*   **Trying a different approach:** If one method isn\\'t working, try something else.\\n\\n**Please provide more context so I can give you a more helpful and relevant response.** I am ready to think harder, but I need a direction to focus my efforts.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a00b503a-a109-41f3-8474-0b4ecb0dc0ba-0', usage_metadata={'input_tokens': 7, 'output_tokens': 484, 'total_tokens': 491, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Workaround"],"metadata":{"id":"-wnCgb7aDC7O"}},{"cell_type":"code","source":["from langchain_core.messages import AIMessage\n","\n","model.invoke(\n","    [\n","        HumanMessage(content=\"Hi! I'm Bob\"),\n","        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n","        HumanMessage(content=\"What's my name?\"),\n","    ]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGMcTHjpDCW1","executionInfo":{"status":"ok","timestamp":1750535533367,"user_tz":-330,"elapsed":682,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"70c899b4-648a-4c88-c6d2-fdf53da17391","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Your name is Bob. You just told me! üòä', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--610b52b7-b2a9-40f6-b073-1d0a652f1b13-0', usage_metadata={'input_tokens': 22, 'output_tokens': 12, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["---\n","# 1.Message Persistence\n"],"metadata":{"id":"e0hLHmAvH_zs"}},{"cell_type":"markdown","source":["Method =\n","\n","Wrapping our ChatModel in LangGraph (default = Simple in-memory checkpointer, or persistent backends (SQLlite, Postgress)"],"metadata":{"id":"UuyICLaUV2Qe"}},{"cell_type":"markdown","source":["Steps =\n","\n","  -> Define a new graph\n","\n","  -> Define the funct that calls the model\n","\n","  -> Define Graph unit node\n","\n","  -> Add Memory\n","\n","\n","  -> create a config (for threads)\n","\n","  ---"],"metadata":{"id":"K_BHCzYhWnvC"}},{"cell_type":"markdown","source":["###### **Langgraph app**\n","Wrap chat model in a min Langgraph app with persisitemt memory"],"metadata":{"id":"L95iHAFFWEXf"}},{"cell_type":"code","source":["from langgraph.checkpoint.memory import MemorySaver\n","from langgraph.graph import START, MessagesState, StateGraph\n","\n","# Define a new graph\n","workflow = StateGraph(state_schema=MessagesState)\n","\n","\n","# Define the function that calls the model\n","def call_model(state: MessagesState):\n","    response = model.invoke(state[\"messages\"])\n","    return {\"messages\": response}\n","\n","\n","# Define the (single) node in the graph\n","workflow.add_edge(START, \"model\")\n","workflow.add_node(\"model\", call_model)\n","\n","# Add memory\n","memory = MemorySaver()\n","app = workflow.compile(checkpointer=memory)"],"metadata":{"id":"lW53-b9RJrVW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### config for Threads"],"metadata":{"id":"-oOuZrTKCAQn"}},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc123\"}}"],"metadata":{"id":"jbIkRD0K3wfd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### invoke the application -->"],"metadata":{"id":"sasUl2El9Ei1"}},{"cell_type":"code","source":["query = \"Hi! I'm Bob.\"\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke({\"messages\": input_messages}, config)\n","output[\"messages\"][-1].pretty_print()  # output contains all messages in state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWxi2MGo9s0n","executionInfo":{"status":"ok","timestamp":1750687206142,"user_tz":-330,"elapsed":775,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"d64be7b6-0303-4b75-ad69-6c03ec89eee2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Hi Bob! It's nice to meet you. How can I help you today?\n"]}]},{"cell_type":"code","source":["query = \"What's my name?\"\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke({\"messages\": input_messages}, config)\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LC8ROaHCSuH","executionInfo":{"status":"ok","timestamp":1750687208903,"user_tz":-330,"elapsed":649,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"3d50b84f-53e1-4cef-aa12-a08a8dedc6a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Your name is Bob. You just told me! üòä\n"]}]},{"cell_type":"markdown","source":["###### new / multi - thread -->"],"metadata":{"id":"ORIAkhKgCnxX"}},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke({\"messages\": input_messages}, config)\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQoWiDWSCqAz","executionInfo":{"status":"ok","timestamp":1750687211973,"user_tz":-330,"elapsed":1547,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"99dafe17-e27d-40bd-b69a-009c13297192"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","As a large language model, I have no memory of past conversations. Therefore, I don't know your name. You haven't told me!\n"]}]},{"cell_type":"code","source":["# we can go back back to Pervious thread where the memory is there\n","config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke({\"messages\": input_messages}, config)\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeGggKtJDMEf","executionInfo":{"status":"ok","timestamp":1750687216462,"user_tz":-330,"elapsed":1468,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"1c45f4e4-5765-4819-ef16-209b836d6fe7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","You told me your name is Bob. Is that correct?\n"]}]},{"cell_type":"markdown","source":["##### **For Async Support**  --> Needs clarity?"],"metadata":{"id":"krV4WpZPEF7u"}},{"cell_type":"code","source":["# Async function for node:\n","async def call_modelA(state: MessagesState):\n","    response = await model.ainvoke(state[\"messages\"])\n","    return {\"messages\": response}\n","\n","\n","# Define graph as before:\n","workflowA = StateGraph(state_schema=MessagesState)\n","workflowA.add_edge(START, \"model\")\n","workflowA.add_node(\"model\", call_modelA)\n","app = workflowA.compile(checkpointer=MemorySaver())\n","\n","# Async invocation:\n","output = await app.ainvoke({\"messages\": input_messages}, config)\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYjQimwNESX2","executionInfo":{"status":"ok","timestamp":1750687186913,"user_tz":-330,"elapsed":2640,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"c06adb56-b420-4b14-f642-017019072ef9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","As a large language model, I don't know your name. I have no memory of past conversations and don't store personal information. You can tell me your name if you'd like!\n"]}]},{"cell_type":"markdown","source":["---\n","# 2.Prompt Template\n"],"metadata":{"id":"YASb0Vp_Vd83"}},{"cell_type":"markdown","source":["### Simple Prompt Temp"],"metadata":{"id":"O6d97onKNoQU"}},{"cell_type":"markdown","source":["###### Add System Message -->\n","--> {create ChatPromptTemplate --> utilize MessagePlaceholder to pass msg in.}\n"],"metadata":{"id":"04A8fRF0GfUV"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")"],"metadata":{"id":"dFrtCQnlVd8-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### Update app -->\n","--> We can now update our application to incorporate this template:"],"metadata":{"id":"KxTgMgBxHWPN"}},{"cell_type":"code","source":["workflow = StateGraph(state_schema=MessagesState)\n","\n","\n","def call_model(state: MessagesState):\n","    prompt = prompt_template.invoke(state)\n","    response = model.invoke(prompt)\n","    return {\"messages\": response}\n","\n","\n","workflow.add_edge(START, \"model\")\n","workflow.add_node(\"model\", call_model)\n","\n","memory = MemorySaver()\n","app = workflow.compile(checkpointer=memory)"],"metadata":{"id":"VFyZ0PphGYyf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n","query = \"Hi! I'm Jim.\"\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke({\"messages\": input_messages}, config)\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxtQX_khHsqn","executionInfo":{"status":"ok","timestamp":1750687734049,"user_tz":-330,"elapsed":872,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"812613d9-8f1a-4253-c14b-855e6733d5d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Ahoy there, Jim! A pleasure to meet ye, matey! I be but a humble parrot, eager to share me knowledge o' the seven seas! What brings ye to me today, savvy?\n"]}]},{"cell_type":"code","source":["query = \"What is my name?\"\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke({\"messages\": input_messages}, config)\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zmTTymCH0z2","executionInfo":{"status":"ok","timestamp":1750687767183,"user_tz":-330,"elapsed":860,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"26d2290e-6140-4495-dc16-d567afe39378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Shiver me timbers, Jim! If ye be askin' me, your name be Jim, just as ye said! A fine name it is, fit for a captain, or at least a swabber who knows his way around a deck!\n"]}]},{"cell_type":"markdown","source":["### Variable in Prompt Temp\n","*Prompt template 2 :  Sytem message 2*"],"metadata":{"id":"afA24dupH72m"}},{"cell_type":"code","source":["prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")"],"metadata":{"id":"ZXX7O3MAIAgu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Update App State** -->\n","coz App now has 2 parameteres : Msg & Lang"],"metadata":{"id":"hpSW8qhyKiCm"}},{"cell_type":"code","source":["from typing import Sequence\n","\n","from langchain_core.messages import BaseMessage\n","from langgraph.graph.message import add_messages\n","from typing_extensions import Annotated, TypedDict\n","\n","#here\n","class State(TypedDict):\n","    messages: Annotated[Sequence[BaseMessage], add_messages]\n","    language: str\n","\n","workflow = StateGraph(state_schema=State)\n","\n","\n","def call_model(state: State):\n","    prompt = prompt_template.invoke(state)\n","    response = model.invoke(prompt)\n","    return {\"messages\": [response]}\n","\n","\n","workflow.add_edge(START, \"model\")\n","workflow.add_node(\"model\", call_model)\n","\n","memory = MemorySaver()\n","app = workflow.compile(checkpointer=memory)"],"metadata":{"id":"reufi56OLB0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n","query = \"Hi! I'm MKV.\"\n","language = \"Hindi\"\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke(\n","    {\"messages\": input_messages, \"language\": language},\n","    config,\n",")\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvgSiaEVN0Au","executionInfo":{"status":"ok","timestamp":1750689354666,"user_tz":-330,"elapsed":781,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"f96d9917-70af-4f11-f749-0d42ebb5f249"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","‡§®‡§Æ‡§∏‡•ç‡§§‡•á MKV! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?\n"]}]},{"cell_type":"markdown","source":["***State is persisted so does the Variable***"],"metadata":{"id":"6JuShQTAOBcs"}},{"cell_type":"code","source":["query = \"What is my name?\"\n","\n","input_messages = [HumanMessage(query)]\n","output = app.invoke(\n","    {\"messages\": input_messages},\n","    config,\n",")\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tq_RoW-dOAQe","executionInfo":{"status":"ok","timestamp":1750689521033,"user_tz":-330,"elapsed":90798,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"3004fe4e-5c34-434e-98ae-8f8c99f4787b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ MKV ‡§π‡•à‡•§\n"]}]},{"cell_type":"markdown","source":["---\n","# 3.Managing Convo History\n"],"metadata":{"id":"vXhyvm1ZVexG"}},{"cell_type":"markdown","source":["##### Trim Message"],"metadata":{"id":"pn7TWMGGPdS6"}},{"cell_type":"code","source":["from langchain_core.messages import SystemMessage, trim_messages, AIMessage\n","\n","trimmer = trim_messages(\n","    max_tokens=65,\n","    strategy=\"last\",\n","    token_counter=model,\n","    include_system=True,\n","    allow_partial=False,\n","    start_on=\"human\",\n",")\n","\n","messages = [\n","    SystemMessage(content=\"you're a good assistant\"),\n","    HumanMessage(content=\"hi! I'm bob\"),\n","    AIMessage(content=\"hi!\"),\n","    HumanMessage(content=\"I like vanilla ice cream\"),\n","    AIMessage(content=\"nice\"),\n","    HumanMessage(content=\"whats 2 + 2\"),\n","    AIMessage(content=\"4\"),\n","    HumanMessage(content=\"thanks\"),\n","    AIMessage(content=\"no problem!\"),\n","    HumanMessage(content=\"having fun?\"),\n","    AIMessage(content=\"yes!\"),\n","]\n","\n","trimmer.invoke(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOrVIDUHVexH","executionInfo":{"status":"ok","timestamp":1750690031289,"user_tz":-330,"elapsed":1229,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"3eb99e5e-9985-45b9-cbc8-fc4da12672c4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n"," AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["##### Update it in App"],"metadata":{"id":"2OSNrJLZRVNO"}},{"cell_type":"code","source":["workflow = StateGraph(state_schema=State)\n","\n","\n","def call_model(state: State):\n","    trimmed_messages = trimmer.invoke(state[\"messages\"])\n","    prompt = prompt_template.invoke(\n","        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n","    )\n","    response = model.invoke(prompt)\n","    return {\"messages\": [response]}\n","\n","\n","workflow.add_edge(START, \"model\")\n","workflow.add_node(\"model\", call_model)\n","\n","memory = MemorySaver()\n","app = workflow.compile(checkpointer=memory)"],"metadata":{"id":"DsTbHOnCRbee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### invoke :\n","*`doesnot remember name coz trimmed ; but remembers what is not trimmed`*"],"metadata":{"id":"c4fwHqzTRr2W"}},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n","query = \"What is my name?\"\n","language = \"English\"\n","\n","input_messages = messages + [HumanMessage(query)]\n","output = app.invoke(\n","    {\"messages\": input_messages, \"language\": language},\n","    config,\n",")\n","output[\"messages\"][-1].pretty_print()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XxVWIXbtRqpX","executionInfo":{"status":"ok","timestamp":1750690417560,"user_tz":-330,"elapsed":5657,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"44d3d3db-8881-4bfd-a844-882284b38764"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I do not have access to personal information, so I don't know your name. You haven't told me!\n"]}]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n","query = \"What math problem did I ask?\"\n","language = \"English\"\n","\n","input_messages = messages + [HumanMessage(query)]\n","output = app.invoke(\n","    {\"messages\": input_messages, \"language\": language},\n","    config,\n",")\n","output[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dz6sMOURSGG-","executionInfo":{"status":"ok","timestamp":1750690464328,"user_tz":-330,"elapsed":5070,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"a69a411f-6147-4d13-ee45-2a3aafff5e85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","You asked \"what's 2 + 2\".\n"]}]},{"cell_type":"markdown","source":["---\n","# 4.Streaming\n"],"metadata":{"id":"BCwk-qcBVfA3"}},{"cell_type":"markdown","source":["*.stream & stream mode*"],"metadata":{"id":"bbAwPI5nT6qe"}},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n","query = \"Hi I'm Todd, please tell me a joke.\"\n","language = \"English\"\n","\n","input_messages = [HumanMessage(query)]\n","for chunk, metadata in app.stream(\n","    {\"messages\": input_messages, \"language\": language},\n","    config,\n","    stream_mode=\"messages\",\n","):\n","    if isinstance(chunk, AIMessage):  # Filter to just model responses\n","        print(chunk.content, end=\"|\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cqg-jgUaVfA3","executionInfo":{"status":"ok","timestamp":1750690916986,"user_tz":-330,"elapsed":799,"user":{"displayName":"CsCps","userId":"14620911368645062286"}},"outputId":"d349bcd3-7154-4bbf-e660-458743c24458"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hi| Todd! Here's a joke for you:\n","\n","Why don't scientists trust atoms|?\n","\n","Because they make up everything!\n","|"]}]}]}